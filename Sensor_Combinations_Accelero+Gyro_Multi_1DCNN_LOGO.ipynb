{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVB1XA8LDc86"
      },
      "source": [
        "\n",
        "# **Deep-Learning Based Human Physical Activity Recognition with Wearable Sensor Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code implements gender recognition utilising wearable sensor data for multiple activities and sensor placements. This particular example utilises all the six measured signals (accelero x, y, z and gyro x, y, z) and applies end-to-end deep learning, fusing readings from multiple sensors for each activity via a multi-head 1D CNN."
      ],
      "metadata": {
        "id": "TfzLr9lp3fm8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC3orRvYnMqI",
        "outputId": "034bf6d3-3831-46e8-933c-77a56308ed49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "%matplotlib inline\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import scipy.io\n",
        "import glob\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import Input, Add, Permute, Reshape, multiply\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot, image\n",
        "from scipy import stats\n",
        "from keras.layers.merge import concatenate\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJonGs4rZmOH",
        "outputId": "ec361d6d-70e6-4283-cbd9-99be6d396850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/HAR Research Project/Datasets\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/HAR Research Project/Datasets')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUrRXDz757hP"
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFHzaLSGdbe3"
      },
      "outputs": [],
      "source": [
        "# Convert to function\n",
        "archive_1 = ZipFile('1.zip', 'r')\n",
        "files_1 = archive_1.namelist()\n",
        "\n",
        "archive_2 = ZipFile('2.zip', 'r')\n",
        "files_2 = archive_2.namelist()\n",
        "\n",
        "archive_3 = ZipFile('3.zip', 'r')\n",
        "files_3 = archive_3.namelist()\n",
        "\n",
        "archive_4 = ZipFile('4.zip', 'r')\n",
        "files_4 = archive_4.namelist()\n",
        "\n",
        "archive_5 = ZipFile('5.zip', 'r')\n",
        "files_5 = archive_5.namelist()\n",
        "\n",
        "archive_6 = ZipFile('6.zip', 'r')\n",
        "files_6 = archive_6.namelist()\n",
        "\n",
        "archive_7 = ZipFile('7.zip', 'r')\n",
        "files_7 = archive_7.namelist()\n",
        "\n",
        "# Convert to function\n",
        "dfs_1 = []\n",
        "for file in files_1[1:]:  #skip .DS_Store\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_1.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_1.append(frame)\n",
        "df_1 = pd.concat(dfs_1,ignore_index=True)\n",
        "#df_1['activity'] = 1\n",
        "\n",
        "dfs_2 = []\n",
        "for file in files_2[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_2.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_2.append(frame)\n",
        "df_2 = pd.concat(dfs_2,ignore_index=True)\n",
        "\n",
        "dfs_3 = []\n",
        "for file in files_3[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_3.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_3.append(frame)\n",
        "df_3 = pd.concat(dfs_3,ignore_index=True)\n",
        "\n",
        "dfs_4 = []\n",
        "for file in files_4[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_4.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_4.append(frame)\n",
        "df_4 = pd.concat(dfs_4,ignore_index=True)\n",
        "\n",
        "dfs_5 = []\n",
        "for file in files_5[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_5.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_5.append(frame)\n",
        "df_5 = pd.concat(dfs_5,ignore_index=True)\n",
        "\n",
        "dfs_6 = []\n",
        "for file in files_6[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_6.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_6.append(frame)\n",
        "df_6 = pd.concat(dfs_6,ignore_index=True)\n",
        "\n",
        "dfs_7 = []\n",
        "for file in files_7[1:]:\n",
        "  # print('Reading:', file)\n",
        "  frame = pd.read_csv(archive_7.open(file), header=None)\n",
        "  frame['filename'] = os.path.basename(file)\n",
        "  dfs_7.append(frame)\n",
        "df_7 = pd.concat(dfs_7,ignore_index=True)\n",
        "\n",
        "pdList = [df_1, df_2, df_3, df_4, df_5, df_6, df_7]  # List of your dataframes\n",
        "raw_df = pd.concat(pdList)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_MBTqaKbDTi"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "E9o1z1SD5ziV",
        "outputId": "4358149f-cb0b-460b-a78f-2f6d59968e43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         x_accelero  y_accelero  z_accelero    x_gyro    y_gyro    z_gyro  \\\n",
              "0         -0.995988   -9.761160   -0.081403 -1.251221  2.136230  0.091553   \n",
              "1         -1.065420   -9.674969   -0.124498 -0.671387  0.579834  1.220703   \n",
              "2         -1.065420   -9.732430   -0.167594 -1.678467 -0.610352  0.732422   \n",
              "3         -1.079785   -9.758766   -0.102951 -1.159668  0.305176  0.183105   \n",
              "4         -1.082179   -9.773131   -0.213084 -0.183105  0.000000 -0.152588   \n",
              "...             ...         ...         ...       ...       ...       ...   \n",
              "4099528   -0.217872   -9.279926   -1.654393 -2.685547  5.126953 -1.892090   \n",
              "4099529    0.196325   -9.339781   -1.697489 -4.241943 -0.488281 -0.335693   \n",
              "4099530    0.548272   -9.232042   -1.563414 -4.608154 -0.976562  2.197266   \n",
              "4099531    0.591368   -9.188946   -1.699883 -4.943848 -0.061035  5.218506   \n",
              "4099532    0.323217   -9.181763   -1.838747 -5.462646  3.967285  7.080078   \n",
              "\n",
              "         activity subject_name trial_number   timestamp  ...  Age  Age Group  \\\n",
              "0               1        amala          1st  1567760697  ...   45          3   \n",
              "1               1        amala          1st  1567760697  ...   45          3   \n",
              "2               1        amala          1st  1567760697  ...   45          3   \n",
              "3               1        amala          1st  1567760697  ...   45          3   \n",
              "4               1        amala          1st  1567760697  ...   45          3   \n",
              "...           ...          ...          ...         ...  ...  ...        ...   \n",
              "4099528         7          van          3rd  1566546471  ...   36          2   \n",
              "4099529         7          van          3rd  1566546471  ...   36          2   \n",
              "4099530         7          van          3rd  1566546471  ...   36          2   \n",
              "4099531         7          van          3rd  1566546471  ...   36          2   \n",
              "4099532         7          van          3rd  1566546471  ...   36          2   \n",
              "\n",
              "         Gender Gender Code  Weight  Height   BMI  Subject_Trial_Number  \\\n",
              "0        Female           0    62.7   168.0  22.2              amala1st   \n",
              "1        Female           0    62.7   168.0  22.2              amala1st   \n",
              "2        Female           0    62.7   168.0  22.2              amala1st   \n",
              "3        Female           0    62.7   168.0  22.2              amala1st   \n",
              "4        Female           0    62.7   168.0  22.2              amala1st   \n",
              "...         ...         ...     ...     ...   ...                   ...   \n",
              "4099528    Male           1    79.0   173.0  26.4                van3rd   \n",
              "4099529    Male           1    79.0   173.0  26.4                van3rd   \n",
              "4099530    Male           1    79.0   173.0  26.4                van3rd   \n",
              "4099531    Male           1    79.0   173.0  26.4                van3rd   \n",
              "4099532    Male           1    79.0   173.0  26.4                van3rd   \n",
              "\n",
              "        Subject_Trial_Sensor_Number Subject_Trial_Sensor_Activity_Number  \n",
              "0                         amala1st1                           amala1st11  \n",
              "1                         amala1st1                           amala1st11  \n",
              "2                         amala1st1                           amala1st11  \n",
              "3                         amala1st1                           amala1st11  \n",
              "4                         amala1st1                           amala1st11  \n",
              "...                             ...                                  ...  \n",
              "4099528                     van3rd5                             van3rd57  \n",
              "4099529                     van3rd5                             van3rd57  \n",
              "4099530                     van3rd5                             van3rd57  \n",
              "4099531                     van3rd5                             van3rd57  \n",
              "4099532                     van3rd5                             van3rd57  \n",
              "\n",
              "[4099533 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a932275-ca4c-4deb-ad62-5cc3d83fc944\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_accelero</th>\n",
              "      <th>y_accelero</th>\n",
              "      <th>z_accelero</th>\n",
              "      <th>x_gyro</th>\n",
              "      <th>y_gyro</th>\n",
              "      <th>z_gyro</th>\n",
              "      <th>activity</th>\n",
              "      <th>subject_name</th>\n",
              "      <th>trial_number</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>...</th>\n",
              "      <th>Age</th>\n",
              "      <th>Age Group</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Gender Code</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Subject_Trial_Number</th>\n",
              "      <th>Subject_Trial_Sensor_Number</th>\n",
              "      <th>Subject_Trial_Sensor_Activity_Number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.995988</td>\n",
              "      <td>-9.761160</td>\n",
              "      <td>-0.081403</td>\n",
              "      <td>-1.251221</td>\n",
              "      <td>2.136230</td>\n",
              "      <td>0.091553</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "      <td>amala1st1</td>\n",
              "      <td>amala1st11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.065420</td>\n",
              "      <td>-9.674969</td>\n",
              "      <td>-0.124498</td>\n",
              "      <td>-0.671387</td>\n",
              "      <td>0.579834</td>\n",
              "      <td>1.220703</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "      <td>amala1st1</td>\n",
              "      <td>amala1st11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.065420</td>\n",
              "      <td>-9.732430</td>\n",
              "      <td>-0.167594</td>\n",
              "      <td>-1.678467</td>\n",
              "      <td>-0.610352</td>\n",
              "      <td>0.732422</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "      <td>amala1st1</td>\n",
              "      <td>amala1st11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.079785</td>\n",
              "      <td>-9.758766</td>\n",
              "      <td>-0.102951</td>\n",
              "      <td>-1.159668</td>\n",
              "      <td>0.305176</td>\n",
              "      <td>0.183105</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "      <td>amala1st1</td>\n",
              "      <td>amala1st11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.082179</td>\n",
              "      <td>-9.773131</td>\n",
              "      <td>-0.213084</td>\n",
              "      <td>-0.183105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.152588</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>...</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "      <td>amala1st1</td>\n",
              "      <td>amala1st11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099528</th>\n",
              "      <td>-0.217872</td>\n",
              "      <td>-9.279926</td>\n",
              "      <td>-1.654393</td>\n",
              "      <td>-2.685547</td>\n",
              "      <td>5.126953</td>\n",
              "      <td>-1.892090</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "      <td>van3rd5</td>\n",
              "      <td>van3rd57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099529</th>\n",
              "      <td>0.196325</td>\n",
              "      <td>-9.339781</td>\n",
              "      <td>-1.697489</td>\n",
              "      <td>-4.241943</td>\n",
              "      <td>-0.488281</td>\n",
              "      <td>-0.335693</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "      <td>van3rd5</td>\n",
              "      <td>van3rd57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099530</th>\n",
              "      <td>0.548272</td>\n",
              "      <td>-9.232042</td>\n",
              "      <td>-1.563414</td>\n",
              "      <td>-4.608154</td>\n",
              "      <td>-0.976562</td>\n",
              "      <td>2.197266</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "      <td>van3rd5</td>\n",
              "      <td>van3rd57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099531</th>\n",
              "      <td>0.591368</td>\n",
              "      <td>-9.188946</td>\n",
              "      <td>-1.699883</td>\n",
              "      <td>-4.943848</td>\n",
              "      <td>-0.061035</td>\n",
              "      <td>5.218506</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "      <td>van3rd5</td>\n",
              "      <td>van3rd57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099532</th>\n",
              "      <td>0.323217</td>\n",
              "      <td>-9.181763</td>\n",
              "      <td>-1.838747</td>\n",
              "      <td>-5.462646</td>\n",
              "      <td>3.967285</td>\n",
              "      <td>7.080078</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "      <td>van3rd5</td>\n",
              "      <td>van3rd57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4099533 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a932275-ca4c-4deb-ad62-5cc3d83fc944')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a932275-ca4c-4deb-ad62-5cc3d83fc944 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a932275-ca4c-4deb-ad62-5cc3d83fc944');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "full_df = raw_df.rename(columns={0: 'x_accelero', 1: 'y_accelero', 2: 'z_accelero', 3 : 'x_gyro', 4: 'y_gyro', 5: 'z_gyro'}, errors=\"raise\")\n",
        "full_df[['activity','subject_name', 'trial_number', 'timestamp', 'sensor_position']] = full_df['filename'].str.split('_',expand=True)\n",
        "full_df[['sensor_position','file_type']] = full_df['sensor_position'].str.split('.',expand=True)\n",
        "full_df.drop(columns=['filename', 'file_type'], inplace=True)\n",
        "gender_df = pd.read_csv('subject_chars_sheet1.csv')\n",
        "full_gd_df = full_df.merge(gender_df, on='subject_name', how='left')\n",
        "\n",
        "full_gd_df['x_accelero'] = pd.to_numeric(full_gd_df['x_accelero'])\n",
        "full_gd_df['y_accelero'] = pd.to_numeric(full_gd_df['y_accelero'])\n",
        "full_gd_df['z_accelero'] = pd.to_numeric(full_gd_df['z_accelero'])\n",
        "\n",
        "full_gd_df['x_gyro'] = pd.to_numeric(full_gd_df['x_gyro'])\n",
        "\n",
        "full_gd_df['y_gyro'] = full_gd_df['y_gyro'].astype('string')\n",
        "full_gd_df['y_gyro'] = full_gd_df['y_gyro'].apply(lambda x: x[:-2] if x[-2:] == \".1\" else x)\n",
        "full_gd_df['y_gyro'] = pd.to_numeric(full_gd_df['y_gyro'])\n",
        "\n",
        "full_gd_df['z_gyro'] = full_gd_df['z_gyro'].astype('string')\n",
        "full_gd_df['z_gyro'] = full_gd_df['z_gyro'].apply(lambda x: x[:-2] if x[-2:] == \".1\" else x)\n",
        "full_gd_df['z_gyro'] = pd.to_numeric(full_gd_df['z_gyro'])\n",
        "\n",
        "full_gd_df['sensor_position'] = pd.to_numeric(full_gd_df['sensor_position'])\n",
        "full_gd_df['activity'] = pd.to_numeric(full_gd_df['activity'])\n",
        "full_gd_df['Gender Code'] = pd.to_numeric(full_gd_df['Gender Code'])\n",
        "\n",
        "full_gd_df[\"Subject_Trial_Number\"] = full_gd_df[\"subject_name\"] + full_gd_df[\"trial_number\"]\n",
        "full_gd_df[\"Subject_Trial_Sensor_Number\"] = full_gd_df[\"subject_name\"] + full_gd_df[\"trial_number\"] + full_gd_df[\"sensor_position\"].astype(str)\n",
        "full_gd_df[\"Subject_Trial_Sensor_Activity_Number\"] = full_gd_df[\"subject_name\"] + full_gd_df[\"trial_number\"] + full_gd_df[\"sensor_position\"].astype(str) + full_gd_df[\"activity\"].astype(str)\n",
        "\n",
        "# This additional line drops subject records where the data is not given or is incomplete for all trials and sensors. \n",
        "# Unlike previous experiments where one subject_trial is left out for 1 sensor at a time, and rest are reshaped and computed, in this experiment sensors are used in parallel\n",
        "# Leave one out returns the indices, therefore if data is missing for a parallel sensor the method would return an error\n",
        "full_gd_df = full_gd_df[(full_gd_df.subject_name != 'Cat') & (full_gd_df.subject_name != 'cheryl') & (full_gd_df.subject_name != 'drdang') & (full_gd_df.subject_name != 'gdil') & (full_gd_df.subject_name != 'thanh') & (full_gd_df.subject_name != 'tuong')]\n",
        "full_gd_df = full_gd_df.reset_index(drop=True)\n",
        "full_gd_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "_WyHKCkJuQT9",
        "outputId": "a8c3f198-c6f7-4a7f-8b48-8550bcf5cd5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0   Age  Age Group   BMI  Gender  Gender Code  Height  \\\n",
              "0         0.0  26.0        1.0  23.1    Male          1.0   173.0   \n",
              "1         0.0  26.0        1.0  23.1    Male          1.0   173.0   \n",
              "2         0.0  26.0        1.0  23.1    Male          1.0   173.0   \n",
              "3         0.0  26.0        1.0  23.1    Male          1.0   173.0   \n",
              "4         0.0  26.0        1.0  23.1    Male          1.0   173.0   \n",
              "...       ...   ...        ...   ...     ...          ...     ...   \n",
              "10079995  0.0   0.0        0.0   0.0  Female          0.0     0.0   \n",
              "10079996  0.0   0.0        0.0   0.0  Female          0.0     0.0   \n",
              "10079997  0.0   0.0        0.0   0.0  Female          0.0     0.0   \n",
              "10079998  0.0   0.0        0.0   0.0  Female          0.0     0.0   \n",
              "10079999  0.0   0.0        0.0   0.0  Female          0.0     0.0   \n",
              "\n",
              "         Subject_Trial_Number Subject_Trial_Sensor_Activity_Number  \\\n",
              "0                   lahiru1st                          lahiru1st41   \n",
              "1                   lahiru1st                          lahiru1st41   \n",
              "2                   lahiru1st                          lahiru1st41   \n",
              "3                   lahiru1st                          lahiru1st41   \n",
              "4                   lahiru1st                          lahiru1st41   \n",
              "...                       ...                                  ...   \n",
              "10079995           drshang3rd                         drshang3rd46   \n",
              "10079996           drshang3rd                         drshang3rd46   \n",
              "10079997           drshang3rd                         drshang3rd46   \n",
              "10079998           drshang3rd                         drshang3rd46   \n",
              "10079999           drshang3rd                         drshang3rd46   \n",
              "\n",
              "         Subject_Trial_Sensor_Number  ...  sensor_position  subject_name  \\\n",
              "0                         lahiru1st4  ...              4.0        lahiru   \n",
              "1                         lahiru1st4  ...              4.0        lahiru   \n",
              "2                         lahiru1st4  ...              4.0        lahiru   \n",
              "3                         lahiru1st4  ...              4.0        lahiru   \n",
              "4                         lahiru1st4  ...              4.0        lahiru   \n",
              "...                              ...  ...              ...           ...   \n",
              "10079995                 drshang3rd4  ...              4.0       drshang   \n",
              "10079996                 drshang3rd4  ...              4.0       drshang   \n",
              "10079997                 drshang3rd4  ...              4.0       drshang   \n",
              "10079998                 drshang3rd4  ...              4.0       drshang   \n",
              "10079999                 drshang3rd4  ...              4.0       drshang   \n",
              "\n",
              "           timestamp trial_number x_accelero    x_gyro  y_accelero    y_gyro  \\\n",
              "0         1565334603          1st  -0.849942  0.396729   -9.114726  0.762939   \n",
              "1         1565334603          1st  -1.055843 -0.946045   -9.131485 -0.213623   \n",
              "2         1565334603          1st  -1.046266 -0.427246   -9.162610  0.793457   \n",
              "3         1565334603          1st  -1.067814 -0.030518   -9.143456  1.861572   \n",
              "4         1565334603          1st  -1.077391  0.000000   -9.119514  2.288818   \n",
              "...              ...          ...        ...       ...         ...       ...   \n",
              "10079995           0          3rd   0.000000  0.000000    0.000000  0.000000   \n",
              "10079996           0          3rd   0.000000  0.000000    0.000000  0.000000   \n",
              "10079997           0          3rd   0.000000  0.000000    0.000000  0.000000   \n",
              "10079998           0          3rd   0.000000  0.000000    0.000000  0.000000   \n",
              "10079999           0          3rd   0.000000  0.000000    0.000000  0.000000   \n",
              "\n",
              "          z_accelero    z_gyro  \n",
              "0          -2.319981  1.403809  \n",
              "1          -2.260126 -0.366211  \n",
              "2          -2.176329  0.274658  \n",
              "3          -2.121263  0.518799  \n",
              "4          -2.214637  0.518799  \n",
              "...              ...       ...  \n",
              "10079995    0.000000  0.000000  \n",
              "10079996    0.000000  0.000000  \n",
              "10079997    0.000000  0.000000  \n",
              "10079998    0.000000  0.000000  \n",
              "10079999    0.000000  0.000000  \n",
              "\n",
              "[10080000 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b535c972-2121-4b5a-8f86-2d4780aee64d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Age</th>\n",
              "      <th>Age Group</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Gender Code</th>\n",
              "      <th>Height</th>\n",
              "      <th>Subject_Trial_Number</th>\n",
              "      <th>Subject_Trial_Sensor_Activity_Number</th>\n",
              "      <th>Subject_Trial_Sensor_Number</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_position</th>\n",
              "      <th>subject_name</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>trial_number</th>\n",
              "      <th>x_accelero</th>\n",
              "      <th>x_gyro</th>\n",
              "      <th>y_accelero</th>\n",
              "      <th>y_gyro</th>\n",
              "      <th>z_accelero</th>\n",
              "      <th>z_gyro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>lahiru1st</td>\n",
              "      <td>lahiru1st41</td>\n",
              "      <td>lahiru1st4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lahiru</td>\n",
              "      <td>1565334603</td>\n",
              "      <td>1st</td>\n",
              "      <td>-0.849942</td>\n",
              "      <td>0.396729</td>\n",
              "      <td>-9.114726</td>\n",
              "      <td>0.762939</td>\n",
              "      <td>-2.319981</td>\n",
              "      <td>1.403809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>lahiru1st</td>\n",
              "      <td>lahiru1st41</td>\n",
              "      <td>lahiru1st4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lahiru</td>\n",
              "      <td>1565334603</td>\n",
              "      <td>1st</td>\n",
              "      <td>-1.055843</td>\n",
              "      <td>-0.946045</td>\n",
              "      <td>-9.131485</td>\n",
              "      <td>-0.213623</td>\n",
              "      <td>-2.260126</td>\n",
              "      <td>-0.366211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>lahiru1st</td>\n",
              "      <td>lahiru1st41</td>\n",
              "      <td>lahiru1st4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lahiru</td>\n",
              "      <td>1565334603</td>\n",
              "      <td>1st</td>\n",
              "      <td>-1.046266</td>\n",
              "      <td>-0.427246</td>\n",
              "      <td>-9.162610</td>\n",
              "      <td>0.793457</td>\n",
              "      <td>-2.176329</td>\n",
              "      <td>0.274658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>lahiru1st</td>\n",
              "      <td>lahiru1st41</td>\n",
              "      <td>lahiru1st4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lahiru</td>\n",
              "      <td>1565334603</td>\n",
              "      <td>1st</td>\n",
              "      <td>-1.067814</td>\n",
              "      <td>-0.030518</td>\n",
              "      <td>-9.143456</td>\n",
              "      <td>1.861572</td>\n",
              "      <td>-2.121263</td>\n",
              "      <td>0.518799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>lahiru1st</td>\n",
              "      <td>lahiru1st41</td>\n",
              "      <td>lahiru1st4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lahiru</td>\n",
              "      <td>1565334603</td>\n",
              "      <td>1st</td>\n",
              "      <td>-1.077391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-9.119514</td>\n",
              "      <td>2.288818</td>\n",
              "      <td>-2.214637</td>\n",
              "      <td>0.518799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>drshang3rd</td>\n",
              "      <td>drshang3rd46</td>\n",
              "      <td>drshang3rd4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>drshang</td>\n",
              "      <td>0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>drshang3rd</td>\n",
              "      <td>drshang3rd46</td>\n",
              "      <td>drshang3rd4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>drshang</td>\n",
              "      <td>0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>drshang3rd</td>\n",
              "      <td>drshang3rd46</td>\n",
              "      <td>drshang3rd4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>drshang</td>\n",
              "      <td>0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>drshang3rd</td>\n",
              "      <td>drshang3rd46</td>\n",
              "      <td>drshang3rd4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>drshang</td>\n",
              "      <td>0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10079999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>drshang3rd</td>\n",
              "      <td>drshang3rd46</td>\n",
              "      <td>drshang3rd4</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>drshang</td>\n",
              "      <td>0</td>\n",
              "      <td>3rd</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10080000 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b535c972-2121-4b5a-8f86-2d4780aee64d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b535c972-2121-4b5a-8f86-2d4780aee64d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b535c972-2121-4b5a-8f86-2d4780aee64d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# the following code ensures all sensors have the same timesteps, before LOGO is called\n",
        "\n",
        "dfs =[]\n",
        "#activity_list = ['amala1st11', 'amala1st12']\n",
        "activity_list = set(full_gd_df.Subject_Trial_Sensor_Activity_Number)\n",
        "for activity in activity_list:\n",
        "  partial_df = full_gd_df[full_gd_df.Subject_Trial_Sensor_Activity_Number == activity]\n",
        "  df_0 = pd.DataFrame([0]*(3000- partial_df.shape[0]))\n",
        "  df = partial_df.append(df_0, ignore_index=True)\n",
        "  for column in ['Gender', 'Gender Code', 'Subject_Trial_Number', 'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number', \n",
        "                 'activity', 'sensor_position', 'subject_name', 'trial_number']:\n",
        "                 df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "  df=df.replace(np.nan,0)\n",
        "  dfs.append(df)\n",
        "final_df = pd.concat(dfs,ignore_index=True)\n",
        "final_df = final_df.reset_index(drop=True)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WeSgjodd1eX"
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('final_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBXTY8VOuYVX"
      },
      "source": [
        "## Function Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfhjK-c53O1t"
      },
      "outputs": [],
      "source": [
        "# Adding learning rate scheduler to optimise above Deep Forward Neural Network\n",
        "\n",
        "# This function keeps the initial learning rate for the first ten epochs and decreases it exponentially after that.\n",
        "def scheduler(epoch, lr):\n",
        "   if epoch < 10:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr * tf.math.exp(-0.1)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler) # call learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3jULSfTuoon"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    \"\"\"\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    \"\"\"\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    # Normalize the confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black.\n",
        "    threshold = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHOwA4vmPlDF"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "partial_df = final_df.drop(columns=[0, \n",
        "                                  'subject_name', 'trial_number','timestamp', \n",
        "                                  'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                  'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "le = preprocessing.LabelEncoder()\n",
        "partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "partial_df_original = partial_df[partial_df[\"activity\"] == 6]\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 1\n",
        "partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == 1]\n",
        "partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN = partial_df_train['Gender Code']\n",
        "X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 2\n",
        "partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == 3]\n",
        "partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "# Both sensor 1 and 2 train sets should have same indices that can be referenced by logo\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "logo = LeaveOneGroupOut()\n",
        "split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "groups = groups.to_numpy()\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "# data for the confusion matrix\n",
        "cm_holder_per_fold = []\n",
        "# create empty lists for later\n",
        "y_true, y_pred = list(), list()\n",
        "\n",
        "for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "    # split data\n",
        "    X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "    y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "    X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train = pd.DataFrame(data = y_train)\n",
        "    y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "    reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "    reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "\n",
        "    # split data\n",
        "    X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "    y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "    X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "    y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "    reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "    reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "    \n",
        "    # defining some input variables\n",
        "    n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "    #model.summary()\n",
        "    #plot_model(model, to_file='model_plot_3.png', show_shapes=True, show_layer_names=True)  \n",
        "    # fit model\n",
        "    history = model.fit([reshaped_X_train,reshaped_X_train_2], reshaped_y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              callbacks=[lr_callback],\n",
        "              validation_data=([reshaped_X_val,reshaped_X_val_2], reshaped_y_val)) # Chnage number of epochs!\n",
        "    \n",
        "    test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2],reshaped_y_test, verbose=0)\n",
        "    acc_per_fold.append(test_scores[1] * 100)\n",
        "    loss_per_fold.append(test_scores[0])\n",
        "    \n",
        "    # Use the model to predict the values from the test data.\n",
        "    predictions_ = model.predict([reshaped_X_test, reshaped_X_test_2])\n",
        "    # Take the class with the highest probability from the test predictions\n",
        "    predictions = np.where(predictions_ > 0.5, 1, 0)\n",
        "    y_pred.append(predictions)\n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = metrics.confusion_matrix(reshaped_y_test, predictions)\n",
        "    \n",
        "    # append the confusion matrix of this fold\n",
        "    cm_holder_per_fold.append(cm)\n",
        "\n",
        "    # store ground truth and predicted values\n",
        "    y_true.append(reshaped_y_test) #[0])\n",
        "    y_pred.append(predictions) #[0])\n",
        "\n",
        "class_names = ['0', '1']\n",
        "\n",
        "# confusion matrix per fold\n",
        "sum_cm_holder_per_fold = []\n",
        "cm_shape = np.array([len(class_names),len(class_names)])\n",
        "for k in range(len(cm_holder_per_fold)):\n",
        "    cm_mask = np.zeros(cm_shape)\n",
        "    cm_mask[:cm_holder_per_fold[k].shape[0], :cm_holder_per_fold[k].shape[1]] = cm_holder_per_fold[k]\n",
        "    sum_cm_holder_per_fold.append(cm_mask)\n",
        "\n",
        "sum_cm_per_fold = sum(sum_cm_holder_per_fold)\n",
        "figure = plot_confusion_matrix(sum_cm_per_fold, class_names=class_names)\n",
        "plt.show()  \n",
        "\n",
        "mean_accuracy = np.mean(acc_per_fold)\n",
        "mean_std = np.std(acc_per_fold)\n",
        "mean_loss = np.mean(loss_per_fold)\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')"
      ],
      "metadata": {
        "id": "pwSmoy2BhCYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr1, tpr1, thresh1 = roc_curve(reshaped_y_test, predictions_, pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(reshaped_y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(reshaped_y_test, random_probs, pos_label=1)\n",
        "\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='1D CNN')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('False Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('True Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC',dpi=300)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "MEWnqFmWMszx",
        "outputId": "0440730e-8b34-447a-ae92-7b2bb07be7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vJaScZJ1V0Zw",
        "outputId": "229d7e2f-dfc2-4b7d-abb7-0844ceda9ade"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Accuracy: 96.87267330628407 (+- 5.907276928702619)\n",
            "> Loss: 1.6667228967328616\n"
          ]
        }
      ],
      "source": [
        "partial_df = final_df.drop(columns=[0, \n",
        "                                  'subject_name', 'trial_number','timestamp', \n",
        "                                  'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                  'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "le = preprocessing.LabelEncoder()\n",
        "partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "partial_df_original = partial_df[partial_df[\"activity\"] == 6]\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 1\n",
        "partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == 1]\n",
        "partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN = partial_df_train['Gender Code']\n",
        "X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 2\n",
        "partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == 3]\n",
        "partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "# Both sensor 1 and 2 train sets should have same indices that can be referenced by logo\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "logo = LeaveOneGroupOut()\n",
        "split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "groups = groups.to_numpy()\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "# data for the confusion matrix\n",
        "cm_holder_per_fold = []\n",
        "# create empty lists for later\n",
        "y_true, y_pred = list(), list()\n",
        "\n",
        "for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "    # split data\n",
        "    X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "    y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "    X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train = pd.DataFrame(data = y_train)\n",
        "    y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "    reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "    reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "\n",
        "    # split data\n",
        "    X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "    y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "    X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "    y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "    reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "    reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "    \n",
        "    # defining some input variables\n",
        "    n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "    #model.summary()\n",
        "    #plot_model(model, to_file='model_plot_3.png', show_shapes=True, show_layer_names=True)  \n",
        "    # fit model\n",
        "    history = model.fit([reshaped_X_train,reshaped_X_train_2], reshaped_y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              callbacks=[lr_callback],\n",
        "              validation_data=([reshaped_X_val,reshaped_X_val_2], reshaped_y_val)) # Chnage number of epochs!\n",
        "    \n",
        "    test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2],reshaped_y_test, verbose=0)\n",
        "    acc_per_fold.append(test_scores[1] * 100)\n",
        "    loss_per_fold.append(test_scores[0])\n",
        "    \n",
        "    # Use the model to predict the values from the test data.\n",
        "    predictions_ = model.predict([reshaped_X_test, reshaped_X_test_2])\n",
        "    # Take the class with the highest probability from the test predictions\n",
        "    predictions = np.where(predictions_ > 0.5, 1, 0)\n",
        "    y_pred.append(predictions)\n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = metrics.confusion_matrix(reshaped_y_test, predictions)\n",
        "    \n",
        "    # append the confusion matrix of this fold\n",
        "    cm_holder_per_fold.append(cm)\n",
        "\n",
        "    # store ground truth and predicted values\n",
        "    y_true.append(reshaped_y_test[0])\n",
        "    y_pred.append(predictions[0])\n",
        "\n",
        "class_names = ['0', '1']\n",
        "\n",
        "# confusion matrix per fold\n",
        "sum_cm_holder_per_fold = []\n",
        "cm_shape = np.array([len(class_names),len(class_names)])\n",
        "for k in range(len(cm_holder_per_fold)):\n",
        "    cm_mask = np.zeros(cm_shape)\n",
        "    cm_mask[:cm_holder_per_fold[k].shape[0], :cm_holder_per_fold[k].shape[1]] = cm_holder_per_fold[k]\n",
        "    sum_cm_holder_per_fold.append(cm_mask)\n",
        "\n",
        "sum_cm_per_fold = sum(sum_cm_holder_per_fold)\n",
        "figure = plot_confusion_matrix(sum_cm_per_fold, class_names=class_names)\n",
        "plt.show()  \n",
        "\n",
        "mean_accuracy = np.mean(acc_per_fold)\n",
        "mean_std = np.std(acc_per_fold)\n",
        "mean_loss = np.mean(loss_per_fold)\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "hF8qLc5hPp1D",
        "outputId": "159f34f8-b694-4bfd-dc41-fa66ffb10523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0fe81db8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0ff12719e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Accuracy: 97.76619521877434 (+- 4.614127315394931)\n",
            "> Loss: 0.4004818095436579\n"
          ]
        }
      ],
      "source": [
        "partial_df = final_df.drop(columns=[0, \n",
        "                                  'subject_name', 'trial_number','timestamp', \n",
        "                                  'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                  'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "le = preprocessing.LabelEncoder()\n",
        "partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "partial_df_original = partial_df[partial_df[\"activity\"] == 6]\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 1\n",
        "partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == 1]\n",
        "partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN = partial_df_train['Gender Code']\n",
        "X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Get data for sensor 2\n",
        "partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == 3]\n",
        "partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "# Standardise\n",
        "scaler = StandardScaler()\n",
        "partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "# Partition Train and Test Data\n",
        "partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "# Define TRAIN X and y variables\n",
        "X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "# Both sensor 1 and 2 train sets should have same indices that can be referenced by logo\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "# Define TEST X and y variables\n",
        "X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "logo = LeaveOneGroupOut()\n",
        "split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "groups = groups.to_numpy()\n",
        "\n",
        "#-------------------------------------------------------------------------------------------\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "# data for the confusion matrix\n",
        "cm_holder_per_fold = []\n",
        "# create empty lists for later\n",
        "y_true, y_pred = list(), list()\n",
        "\n",
        "for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "    # split data\n",
        "    X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "    y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "    X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train = pd.DataFrame(data = y_train)\n",
        "    y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "    reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "    reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "\n",
        "    # split data\n",
        "    X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "    y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "    X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "    y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "    y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "    reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "    reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "    #-------------------------------------------------------------------------------------------\n",
        "    \n",
        "    # defining some input variables\n",
        "    n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "    # getting the model\n",
        "    model = cnn_model_creation(n_timesteps, n_features)\n",
        "    #model.summary()\n",
        "    #plot_model(model, to_file='model_plot_3.png', show_shapes=True, show_layer_names=True)  \n",
        "    # fit model\n",
        "    history = model.fit([reshaped_X_train,reshaped_X_train_2], reshaped_y_train,\n",
        "              epochs=100,\n",
        "              verbose=0,\n",
        "              callbacks=[lr_callback],\n",
        "              validation_data=([reshaped_X_val,reshaped_X_val_2], reshaped_y_val)) # Chnage number of epochs!\n",
        "    \n",
        "    test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2],reshaped_y_test, verbose=0)\n",
        "    acc_per_fold.append(test_scores[1] * 100)\n",
        "    loss_per_fold.append(test_scores[0])\n",
        "    \n",
        "    # Use the model to predict the values from the test data.\n",
        "    predictions_ = model.predict([reshaped_X_test, reshaped_X_test_2])\n",
        "    # Take the class with the highest probability from the test predictions\n",
        "    predictions = np.where(predictions_ > 0.5, 1, 0)\n",
        "    y_pred.append(predictions)\n",
        "    # Calculate the confusion matrix using sklearn.metrics\n",
        "    cm = metrics.confusion_matrix(reshaped_y_test, predictions)\n",
        "    \n",
        "    # append the confusion matrix of this fold\n",
        "    cm_holder_per_fold.append(cm)\n",
        "\n",
        "    # store ground truth and predicted values\n",
        "    y_true.append(reshaped_y_test[0])\n",
        "    y_pred.append(predictions[0])\n",
        "\n",
        "class_names = ['0', '1']\n",
        "\n",
        "# confusion matrix per fold\n",
        "sum_cm_holder_per_fold = []\n",
        "cm_shape = np.array([len(class_names),len(class_names)])\n",
        "for k in range(len(cm_holder_per_fold)):\n",
        "    cm_mask = np.zeros(cm_shape)\n",
        "    cm_mask[:cm_holder_per_fold[k].shape[0], :cm_holder_per_fold[k].shape[1]] = cm_holder_per_fold[k]\n",
        "    sum_cm_holder_per_fold.append(cm_mask)\n",
        "\n",
        "sum_cm_per_fold = sum(sum_cm_holder_per_fold)\n",
        "figure = plot_confusion_matrix(sum_cm_per_fold, class_names=class_names)\n",
        "plt.show()  \n",
        "\n",
        "mean_accuracy = np.mean(acc_per_fold)\n",
        "mean_std = np.std(acc_per_fold)\n",
        "mean_loss = np.mean(loss_per_fold)\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cJTr25A3R0L"
      },
      "source": [
        "## 2 Parallel Sensors "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaKObCBKXB4o"
      },
      "outputs": [],
      "source": [
        "# Multi-headed 1D CNN\n",
        "def cnn_model_creation(n_timesteps, n_features):\n",
        "    # head 1\n",
        "    inputs1 = Input(shape=(n_timesteps,n_features))\n",
        "    conv1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs1) #change kernel size to 5 \n",
        "    bn1 = BatchNormalization()(conv1)\n",
        "    pool1 = GlobalAveragePooling1D()(bn1) \n",
        "    flat1 = Flatten()(pool1)\n",
        "\n",
        "    # head 2\n",
        "    inputs2 = Input(shape=(n_timesteps,n_features))\n",
        "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs2)\n",
        "    bn2 = BatchNormalization()(conv2)\n",
        "    pool2 = GlobalAveragePooling1D()(bn2)\n",
        "    flat2 = Flatten()(pool2)\n",
        "\n",
        "    # merge\n",
        "    merged = concatenate([flat1, flat2])\n",
        "\n",
        "    # interpretation\n",
        "    dense1 = Dense(16, activation='relu', kernel_regularizer='l2')(merged) #16\n",
        "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "    # save a plot of the model\n",
        "    # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#GlobalAveragePooling1D - check results after changing to this!! *CHECK* #MaxPooling1D(pool_size=2)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def get_frames(X, Y):\n",
        "  \n",
        "  N_FEATURES = 6\n",
        "\n",
        "  frames = []\n",
        "  labels = []\n",
        "  for Subject_Trial_Number_Encoded in set(X.Subject_Trial_Number_Encoded):  #for each group\n",
        "    current_frame = X.loc[X.Subject_Trial_Number_Encoded == Subject_Trial_Number_Encoded]  #get the all the frames for that group\n",
        "    start_index = min(current_frame.index)\n",
        "    end_index = max(current_frame.index) + 1\n",
        "    frame_size = len(current_frame)\n",
        "\n",
        "    ax = X['x_accelero'].values[start_index: end_index] \n",
        "    ay = X['y_accelero'].values[start_index: end_index]\n",
        "    az = X['z_accelero'].values[start_index: end_index]\n",
        "    gx = X['x_gyro'].values[start_index: end_index] \n",
        "    gy = X['y_gyro'].values[start_index: end_index]\n",
        "    gz = X['z_gyro'].values[start_index: end_index]\n",
        "\n",
        "    # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(Y[start_index: end_index])[0][0]\n",
        "    \n",
        "    frames.append([ax, ay, az, gx, gy, gz])\n",
        "    labels.append(label)\n",
        "  # returns frames of samples, each sample(group) with three features, each feature with n timesteps 28*3*1729 i.e. groups/samples * features * timesteps\n",
        "\n",
        "  # As the frame size differes for each group, the frames are padded\n",
        "  padded_frames = []\n",
        "  for row in frames:\n",
        "    shape = np.shape(row)\n",
        "    padded_array = np.zeros((6, 3000)) \n",
        "    padded_array[:shape[0],:shape[1]] = row\n",
        "    padded_frames.append(padded_array)\n",
        "\n",
        "  # return exactly the same shape as above but padded so each group has same number of steps - might not need this for this experiment! *CHECK*\n",
        "\n",
        "  # Bring the segments into a better shape\n",
        "  reshaped_padded_frames = np.transpose(padded_frames, (0, 2, 1))\n",
        "  reshaped_labels = np.asarray(labels)\n",
        "  \n",
        "  # finally converts the  28*3*1729  -> 28*1729*3 i.e. groups/samples * timestep * features\n",
        "  return reshaped_padded_frames, reshaped_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTznjrkNZOIN"
      },
      "outputs": [],
      "source": [
        "def get_scores(sensor_position_number, activity_number, full_gd_df): \n",
        "\n",
        "  partial_df = final_df.drop(columns=[0, \n",
        "                                    'subject_name', 'trial_number','timestamp', \n",
        "                                    'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                    'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "  partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "  partial_df_original = partial_df[partial_df[\"activity\"] == activity_number]\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 1\n",
        "  partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[0]]\n",
        "  partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN = partial_df_train['Gender Code']\n",
        "  X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "  y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 2\n",
        "  partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[1]]\n",
        "  partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "  X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "  y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "  # Both sensor 1 and 2 train sets should have same indices that can be referenced by logo\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "  logo = LeaveOneGroupOut()\n",
        "  split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "  groups = groups.to_numpy()\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "\n",
        "  for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "      # split data\n",
        "      X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "      y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "      X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train = pd.DataFrame(data = y_train)\n",
        "      y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "      reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "      reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "      y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "      X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "      y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "      reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "      reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "      \n",
        "      # defining some input variables\n",
        "      n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "      # getting the model\n",
        "      model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "      # fit model\n",
        "      history = model.fit([reshaped_X_train,reshaped_X_train_2], reshaped_y_train,\n",
        "                epochs=50,\n",
        "                verbose=0,\n",
        "                callbacks=[lr_callback],\n",
        "                validation_data=([reshaped_X_val,reshaped_X_val_2], reshaped_y_val)) # Chnage number of epochs!\n",
        "      \n",
        "      test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2],reshaped_y_test, verbose=0)\n",
        "      acc_per_fold.append(test_scores[1] * 100)\n",
        "      loss_per_fold.append(test_scores[0])\n",
        "  mean_accuracy = np.mean(acc_per_fold)\n",
        "  mean_std = np.std(acc_per_fold)\n",
        "  mean_loss = np.mean(loss_per_fold)\n",
        "  print('Sensor:', sensor_position_number, 'Activity:', activity_number)\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Std6-buMH4",
        "outputId": "ff62f6a0-58c0-49e7-ef05-2ccbd1fbf863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 3] Activity: 6\n",
            "> Accuracy: 96.27699203129056 (+- 6.360135586375492)\n",
            "> Loss: 0.4929330141483983\n",
            "Sensor: [1, 3] Activity: 7\n",
            "> Accuracy: 92.25614342508437 (+- 6.453595648104264)\n",
            "> Loss: 0.4899911533428144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(6, [1, 3], 96.27699203129056), (7, [1, 3], 92.25614342508437)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [6, 7]\n",
        "sensor_list = [\n",
        "              [1,3]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz26H3Ii28GQ",
        "outputId": "fd518bdc-3b4b-45ca-f96f-8140dd7b80b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 2] Activity: 1\n",
            "> Accuracy: 51.3030543923378 (+- 14.52793977166662)\n",
            "> Loss: 0.6957320374778554\n",
            "Sensor: [1, 3] Activity: 1\n",
            "> Accuracy: 81.83172111269793 (+- 6.630717955007186)\n",
            "> Loss: 0.4862276813651942\n",
            "Sensor: [1, 4] Activity: 1\n",
            "> Accuracy: 55.24944353707229 (+- 6.167172311113306)\n",
            "> Loss: 0.659310839598692\n",
            "Sensor: [1, 5] Activity: 1\n",
            "> Accuracy: 65.74832649925087 (+- 9.938688497059582)\n",
            "> Loss: 0.6510754627517507\n",
            "Sensor: [2, 3] Activity: 1\n",
            "> Accuracy: 60.83395549013645 (+- 11.420354448622362)\n",
            "> Loss: 0.6445856630047665\n",
            "Sensor: [2, 4] Activity: 1\n",
            "> Accuracy: 33.28369389983672 (+- 9.447348778411575)\n",
            "> Loss: 0.9304045634933665\n",
            "Sensor: [2, 5] Activity: 1\n",
            "> Accuracy: 26.656739159098155 (+- 8.969282510295166)\n",
            "> Loss: 0.9998920559883118\n",
            "Sensor: [3, 4] Activity: 1\n",
            "> Accuracy: 65.74832661242425 (+- 10.743442625342835)\n",
            "> Loss: 0.6619820919217942\n",
            "Sensor: [3, 5] Activity: 1\n",
            "> Accuracy: 54.653762111180946 (+- 8.379333319470879)\n",
            "> Loss: 0.7094267976434925\n",
            "Sensor: [4, 5] Activity: 1\n",
            "> Accuracy: 31.124349579780915 (+- 3.2626807578817307)\n",
            "> Loss: 0.972764439975159\n",
            "Sensor: [1, 2] Activity: 2\n",
            "> Accuracy: 49.06924930931647 (+- 15.880452637577596)\n",
            "> Loss: 0.7157003894636903\n",
            "Sensor: [1, 3] Activity: 2\n",
            "> Accuracy: 79.82129677187038 (+- 5.590961663716882)\n",
            "> Loss: 0.5111795954311951\n",
            "Sensor: [1, 4] Activity: 2\n",
            "> Accuracy: 55.621744220769855 (+- 8.148541914914153)\n",
            "> Loss: 0.6601748715473127\n",
            "Sensor: [1, 5] Activity: 2\n",
            "> Accuracy: 76.69397011587891 (+- 7.9110196239502555)\n",
            "> Loss: 0.617562901370133\n",
            "Sensor: [2, 3] Activity: 2\n",
            "> Accuracy: 61.42963684057887 (+- 11.755276992556158)\n",
            "> Loss: 0.6580190224738061\n",
            "Sensor: [2, 4] Activity: 2\n",
            "> Accuracy: 31.720030458667612 (+- 9.332208685183197)\n",
            "> Loss: 0.9786749821674975\n",
            "Sensor: [2, 5] Activity: 2\n",
            "> Accuracy: 20.104244672044924 (+- 7.2260897641321025)\n",
            "> Loss: 0.9723084418079521\n",
            "Sensor: [3, 4] Activity: 2\n",
            "> Accuracy: 72.37528087217596 (+- 9.561101988132954)\n",
            "> Loss: 0.6379326453691796\n",
            "Sensor: [3, 5] Activity: 2\n",
            "> Accuracy: 60.461655032785636 (+- 8.925286216110047)\n",
            "> Loss: 0.6807428870020034\n",
            "Sensor: [4, 5] Activity: 2\n",
            "> Accuracy: 29.039464721196815 (+- 6.0902771638841555)\n",
            "> Loss: 0.9162806951546971\n",
            "Sensor: [1, 2] Activity: 3\n",
            "> Accuracy: 44.1548780172686 (+- 8.36476378832423)\n",
            "> Loss: 0.9024513499646247\n",
            "Sensor: [1, 3] Activity: 3\n",
            "> Accuracy: 63.29114105128035 (+- 11.660566145359319)\n",
            "> Loss: 0.620868141138101\n",
            "Sensor: [1, 4] Activity: 3\n",
            "> Accuracy: 43.33581639618813 (+- 9.779542977508825)\n",
            "> Loss: 0.7848101054565816\n",
            "Sensor: [1, 5] Activity: 3\n",
            "> Accuracy: 55.02606254966953 (+- 12.593237376486755)\n",
            "> Loss: 0.7251222480701495\n",
            "Sensor: [2, 3] Activity: 3\n",
            "> Accuracy: 40.72971059174477 (+- 10.905809125558006)\n",
            "> Loss: 0.8285471148128751\n",
            "Sensor: [2, 4] Activity: 3\n",
            "> Accuracy: 27.02904007857359 (+- 6.973861519622215)\n",
            "> Loss: 1.0431942230538478\n",
            "Sensor: [2, 5] Activity: 3\n",
            "> Accuracy: 23.23157154495203 (+- 11.227447371977789)\n",
            "> Loss: 1.0196508010731469\n",
            "Sensor: [3, 4] Activity: 3\n",
            "> Accuracy: 51.005213792565506 (+- 10.283593530347225)\n",
            "> Loss: 0.7567504018167907\n",
            "Sensor: [3, 5] Activity: 3\n",
            "> Accuracy: 48.250187537338164 (+- 7.962713716973628)\n",
            "> Loss: 0.7516706095466131\n",
            "Sensor: [4, 5] Activity: 3\n",
            "> Accuracy: 29.113924682517595 (+- 9.900682296751814)\n",
            "> Loss: 0.9420825348624701\n",
            "Sensor: [1, 2] Activity: 4\n",
            "> Accuracy: 46.314223054089126 (+- 6.90113645177003)\n",
            "> Loss: 0.7352823373637621\n",
            "Sensor: [1, 3] Activity: 4\n",
            "> Accuracy: 63.961282787443714 (+- 7.624807773773428)\n",
            "> Loss: 0.6626180093499678\n",
            "Sensor: [1, 4] Activity: 4\n",
            "> Accuracy: 63.29114101355589 (+- 10.76200548834403)\n",
            "> Loss: 0.6490113056158717\n",
            "Sensor: [1, 5] Activity: 4\n",
            "> Accuracy: 59.493672772298886 (+- 9.590053174512558)\n",
            "> Loss: 0.7537369539466086\n",
            "Sensor: [2, 3] Activity: 4\n",
            "> Accuracy: 29.113924710810938 (+- 6.9347963329301106)\n",
            "> Loss: 0.8414659982995142\n",
            "Sensor: [2, 4] Activity: 4\n",
            "> Accuracy: 30.82650857447069 (+- 9.645968899421533)\n",
            "> Loss: 0.90879307064829\n",
            "Sensor: [2, 5] Activity: 4\n",
            "> Accuracy: 10.498883179094218 (+- 7.169087152200127)\n",
            "> Loss: 0.9669231515896471\n",
            "Sensor: [3, 4] Activity: 4\n",
            "> Accuracy: 36.93224206755433 (+- 11.725052948418668)\n",
            "> Loss: 0.8175721213787417\n",
            "Sensor: [3, 5] Activity: 4\n",
            "> Accuracy: 39.687268285057215 (+- 11.670072407888414)\n",
            "> Loss: 0.9251238930074475\n",
            "Sensor: [4, 5] Activity: 4\n",
            "> Accuracy: 22.263589388207546 (+- 13.258510131039165)\n",
            "> Loss: 0.9490461145775227\n",
            "Sensor: [1, 2] Activity: 5\n",
            "> Accuracy: 58.600150633461865 (+- 12.7111157033831)\n",
            "> Loss: 0.68264893414099\n",
            "Sensor: [1, 3] Activity: 5\n",
            "> Accuracy: 81.16157967833024 (+- 3.0154066305903973)\n",
            "> Loss: 0.4902659122702442\n",
            "Sensor: [1, 4] Activity: 5\n",
            "> Accuracy: 77.21519123149824 (+- 6.019771176981514)\n",
            "> Loss: 0.5469122612023656\n",
            "Sensor: [1, 5] Activity: 5\n",
            "> Accuracy: 50.930753991573674 (+- 10.031970559022342)\n",
            "> Loss: 0.7853213480756253\n",
            "Sensor: [2, 3] Activity: 5\n",
            "> Accuracy: 44.97394003445589 (+- 8.781881639677286)\n",
            "> Loss: 0.8356497129307517\n",
            "Sensor: [2, 4] Activity: 5\n",
            "> Accuracy: 39.46388765603681 (+- 11.620557916447806)\n",
            "> Loss: 0.9212584344646598\n",
            "Sensor: [2, 5] Activity: 5\n",
            "> Accuracy: 15.636634609744519 (+- 6.676548824150594)\n",
            "> Loss: 1.158981797061389\n",
            "Sensor: [3, 4] Activity: 5\n",
            "> Accuracy: 72.59866135029853 (+- 7.362901285236778)\n",
            "> Loss: 0.5675587510760827\n",
            "Sensor: [3, 5] Activity: 5\n",
            "> Accuracy: 41.548772401447536 (+- 7.330451361735107)\n",
            "> Loss: 0.8858712677714191\n",
            "Sensor: [4, 5] Activity: 5\n",
            "> Accuracy: 34.40059644134739 (+- 8.68411123636327)\n",
            "> Loss: 0.9603014271470565\n",
            "Sensor: [1, 2] Activity: 6\n",
            "> Accuracy: 75.50260756589189 (+- 7.965497139704129)\n",
            "> Loss: 0.6275534690180912\n",
            "Sensor: [1, 3] Activity: 6\n",
            "> Accuracy: 96.35145219066474 (+- 5.71648445976812)\n",
            "> Loss: 0.4965852785714065\n",
            "Sensor: [1, 4] Activity: 6\n",
            "> Accuracy: 80.56589840333673 (+- 8.896664864352624)\n",
            "> Loss: 0.5622356786758085\n",
            "Sensor: [1, 5] Activity: 6\n",
            "> Accuracy: 49.516010397597206 (+- 10.818526858430143)\n",
            "> Loss: 0.7077592075625553\n",
            "Sensor: [2, 3] Activity: 6\n",
            "> Accuracy: 45.12286039092873 (+- 9.39320255846006)\n",
            "> Loss: 0.7529309950297391\n",
            "Sensor: [2, 4] Activity: 6\n",
            "> Accuracy: 27.326880753794804 (+- 11.154620075659416)\n",
            "> Loss: 0.9424891834017597\n",
            "Sensor: [2, 5] Activity: 6\n",
            "> Accuracy: 28.592703670640535 (+- 6.66657634798235)\n",
            "> Loss: 1.0763943708395656\n",
            "Sensor: [3, 4] Activity: 6\n",
            "> Accuracy: 65.52494605885276 (+- 10.494921343146274)\n",
            "> Loss: 0.5939079930510702\n",
            "Sensor: [3, 5] Activity: 6\n",
            "> Accuracy: 53.611320445809184 (+- 4.184369985212888)\n",
            "> Loss: 0.8378069838391075\n",
            "Sensor: [4, 5] Activity: 6\n",
            "> Accuracy: 27.773641672315478 (+- 7.000047729224084)\n",
            "> Loss: 1.0034371229666699\n",
            "Sensor: [1, 2] Activity: 7\n",
            "> Accuracy: 61.355176869826984 (+- 9.202987245409746)\n",
            "> Loss: 0.7023912434336506\n",
            "Sensor: [1, 3] Activity: 7\n",
            "> Accuracy: 92.107223106336 (+- 7.480930355356525)\n",
            "> Loss: 0.49128551422795164\n",
            "Sensor: [1, 4] Activity: 7\n",
            "> Accuracy: 69.76917510545707 (+- 11.063787951850548)\n",
            "> Loss: 0.6095073917244054\n",
            "Sensor: [1, 5] Activity: 7\n",
            "> Accuracy: 41.10201133202903 (+- 8.854187294025916)\n",
            "> Loss: 0.7473857546154457\n",
            "Sensor: [2, 3] Activity: 7\n",
            "> Accuracy: 49.44155012504964 (+- 15.222324294683233)\n",
            "> Loss: 0.7694761564459982\n",
            "Sensor: [2, 4] Activity: 7\n",
            "> Accuracy: 30.752048424527615 (+- 15.519542215558364)\n",
            "> Loss: 0.8841876998732362\n",
            "Sensor: [2, 5] Activity: 7\n",
            "> Accuracy: 20.10424469090715 (+- 4.642876462337043)\n",
            "> Loss: 1.0842337774325022\n",
            "Sensor: [3, 4] Activity: 7\n",
            "> Accuracy: 79.30007546762877 (+- 19.246475314302124)\n",
            "> Loss: 0.5649085735218434\n",
            "Sensor: [3, 5] Activity: 7\n",
            "> Accuracy: 53.01563932171351 (+- 2.193733689867657)\n",
            "> Loss: 0.7708233232739605\n",
            "Sensor: [4, 5] Activity: 7\n",
            "> Accuracy: 32.24125163087362 (+- 12.19829350685686)\n",
            "> Loss: 0.9419698254971565\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(1, [1, 2], 51.3030543923378),\n",
              " (1, [1, 3], 81.83172111269793),\n",
              " (1, [1, 4], 55.24944353707229),\n",
              " (1, [1, 5], 65.74832649925087),\n",
              " (1, [2, 3], 60.83395549013645),\n",
              " (1, [2, 4], 33.28369389983672),\n",
              " (1, [2, 5], 26.656739159098155),\n",
              " (1, [3, 4], 65.74832661242425),\n",
              " (1, [3, 5], 54.653762111180946),\n",
              " (1, [4, 5], 31.124349579780915),\n",
              " (2, [1, 2], 49.06924930931647),\n",
              " (2, [1, 3], 79.82129677187038),\n",
              " (2, [1, 4], 55.621744220769855),\n",
              " (2, [1, 5], 76.69397011587891),\n",
              " (2, [2, 3], 61.42963684057887),\n",
              " (2, [2, 4], 31.720030458667612),\n",
              " (2, [2, 5], 20.104244672044924),\n",
              " (2, [3, 4], 72.37528087217596),\n",
              " (2, [3, 5], 60.461655032785636),\n",
              " (2, [4, 5], 29.039464721196815),\n",
              " (3, [1, 2], 44.1548780172686),\n",
              " (3, [1, 3], 63.29114105128035),\n",
              " (3, [1, 4], 43.33581639618813),\n",
              " (3, [1, 5], 55.02606254966953),\n",
              " (3, [2, 3], 40.72971059174477),\n",
              " (3, [2, 4], 27.02904007857359),\n",
              " (3, [2, 5], 23.23157154495203),\n",
              " (3, [3, 4], 51.005213792565506),\n",
              " (3, [3, 5], 48.250187537338164),\n",
              " (3, [4, 5], 29.113924682517595),\n",
              " (4, [1, 2], 46.314223054089126),\n",
              " (4, [1, 3], 63.961282787443714),\n",
              " (4, [1, 4], 63.29114101355589),\n",
              " (4, [1, 5], 59.493672772298886),\n",
              " (4, [2, 3], 29.113924710810938),\n",
              " (4, [2, 4], 30.82650857447069),\n",
              " (4, [2, 5], 10.498883179094218),\n",
              " (4, [3, 4], 36.93224206755433),\n",
              " (4, [3, 5], 39.687268285057215),\n",
              " (4, [4, 5], 22.263589388207546),\n",
              " (5, [1, 2], 58.600150633461865),\n",
              " (5, [1, 3], 81.16157967833024),\n",
              " (5, [1, 4], 77.21519123149824),\n",
              " (5, [1, 5], 50.930753991573674),\n",
              " (5, [2, 3], 44.97394003445589),\n",
              " (5, [2, 4], 39.46388765603681),\n",
              " (5, [2, 5], 15.636634609744519),\n",
              " (5, [3, 4], 72.59866135029853),\n",
              " (5, [3, 5], 41.548772401447536),\n",
              " (5, [4, 5], 34.40059644134739),\n",
              " (6, [1, 2], 75.50260756589189),\n",
              " (6, [1, 3], 96.35145219066474),\n",
              " (6, [1, 4], 80.56589840333673),\n",
              " (6, [1, 5], 49.516010397597206),\n",
              " (6, [2, 3], 45.12286039092873),\n",
              " (6, [2, 4], 27.326880753794804),\n",
              " (6, [2, 5], 28.592703670640535),\n",
              " (6, [3, 4], 65.52494605885276),\n",
              " (6, [3, 5], 53.611320445809184),\n",
              " (6, [4, 5], 27.773641672315478),\n",
              " (7, [1, 2], 61.355176869826984),\n",
              " (7, [1, 3], 92.107223106336),\n",
              " (7, [1, 4], 69.76917510545707),\n",
              " (7, [1, 5], 41.10201133202903),\n",
              " (7, [2, 3], 49.44155012504964),\n",
              " (7, [2, 4], 30.752048424527615),\n",
              " (7, [2, 5], 20.10424469090715),\n",
              " (7, [3, 4], 79.30007546762877),\n",
              " (7, [3, 5], 53.01563932171351),\n",
              " (7, [4, 5], 32.24125163087362)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2]\n",
        "              ,[1,3]\n",
        "              ,[1,4]\n",
        "              ,[1,5]\n",
        "              ,[2,3]\n",
        "              ,[2,4]\n",
        "              ,[2,5]\n",
        "              ,[3,4]\n",
        "              ,[3,5]\n",
        "              ,[4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2VAYa_53dq8"
      },
      "source": [
        "## 3 Parallel Sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqVj09ZM3gGR"
      },
      "outputs": [],
      "source": [
        "# Multi-headed 1D CNN\n",
        "def cnn_model_creation(n_timesteps, n_features):\n",
        "    # head 1\n",
        "    inputs1 = Input(shape=(n_timesteps,n_features))\n",
        "    conv1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs1)\n",
        "    bn1 = BatchNormalization()(conv1)\n",
        "    pool1 = GlobalAveragePooling1D()(bn1) \n",
        "    flat1 = Flatten()(pool1)\n",
        "\n",
        "    # head 2\n",
        "    inputs2 = Input(shape=(n_timesteps,n_features))\n",
        "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs2)\n",
        "    bn2 = BatchNormalization()(conv2)\n",
        "    pool2 = GlobalAveragePooling1D()(bn2)\n",
        "    flat2 = Flatten()(pool2)\n",
        "\n",
        "    # head 3\n",
        "    inputs3 = Input(shape=(n_timesteps,n_features))\n",
        "    conv3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs3)\n",
        "    bn3 = BatchNormalization()(conv3)\n",
        "    pool3 = GlobalAveragePooling1D()(bn3)\n",
        "    flat3 = Flatten()(pool3)\n",
        "\n",
        "    # merge\n",
        "    merged = concatenate([flat1,flat2,flat3])\n",
        "\n",
        "    # interpretation\n",
        "    dense1 = Dense(16, activation='relu')(merged) #16\n",
        "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "\n",
        "    # save a plot of the model\n",
        "    # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#GlobalAveragePooling1D - check results after changing to this!! *CHECK* #MaxPooling1D(pool_size=2)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def get_frames(X, Y):\n",
        "  \n",
        "  N_FEATURES = 6\n",
        "\n",
        "  frames = []\n",
        "  labels = []\n",
        "  for Subject_Trial_Number_Encoded in set(X.Subject_Trial_Number_Encoded):  #for each group\n",
        "    current_frame = X.loc[X.Subject_Trial_Number_Encoded == Subject_Trial_Number_Encoded]  #get the all the frames for that group\n",
        "    start_index = min(current_frame.index)\n",
        "    end_index = max(current_frame.index) + 1\n",
        "    frame_size = len(current_frame)\n",
        "\n",
        "    ax = X['x_accelero'].values[start_index: end_index] \n",
        "    ay = X['y_accelero'].values[start_index: end_index]\n",
        "    az = X['z_accelero'].values[start_index: end_index]\n",
        "    gx = X['x_gyro'].values[start_index: end_index] \n",
        "    gy = X['y_gyro'].values[start_index: end_index]\n",
        "    gz = X['z_gyro'].values[start_index: end_index]\n",
        "\n",
        "    # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(Y[start_index: end_index])[0][0]\n",
        "    \n",
        "    frames.append([ax, ay, az, gx, gy, gz])\n",
        "    labels.append(label)\n",
        "  # returns frames of samples, each sample(group) with three features, each feature with n timesteps 28*3*1729 i.e. groups/samples * features * timesteps\n",
        "\n",
        "  # As the frame size differes for each group, the frames are padded\n",
        "  padded_frames = []\n",
        "  for row in frames:\n",
        "    shape = np.shape(row)\n",
        "    padded_array = np.zeros((6, 3000)) \n",
        "    padded_array[:shape[0],:shape[1]] = row\n",
        "    padded_frames.append(padded_array)\n",
        "\n",
        "  # return exactly the same shape as above but padded so each group has same number of steps - might not need this for this experiment! *CHECK*\n",
        "\n",
        "  # Bring the segments into a better shape\n",
        "  reshaped_padded_frames = np.transpose(padded_frames, (0, 2, 1))\n",
        "  reshaped_labels = np.asarray(labels)\n",
        "  \n",
        "  # finally converts the  28*3*1729  -> 28*1729*3 i.e. groups/samples * timestep * features\n",
        "  return reshaped_padded_frames, reshaped_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUJYCzGZ3gMv"
      },
      "outputs": [],
      "source": [
        "def get_scores(sensor_position_number, activity_number, full_gd_df): \n",
        "\n",
        "  partial_df = final_df.drop(columns=[0, \n",
        "                                    'subject_name', 'trial_number','timestamp', \n",
        "                                    'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                    'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "  partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "  partial_df_original = partial_df[partial_df[\"activity\"] == activity_number]\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 1\n",
        "  partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[0]]\n",
        "  partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN = partial_df_train['Gender Code']\n",
        "  X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "  y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 2\n",
        "  partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[1]]\n",
        "  partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "  X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "  y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 3\n",
        "  partial_df_3 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[2]]\n",
        "  partial_df_3 = partial_df_3.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_3[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_3 = partial_df_train_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_3 = partial_df_train_3['Gender Code']\n",
        "  X_TRAIN_3 = X_TRAIN_3.to_numpy() # for LOGO\n",
        "  y_TRAIN_3 = y_TRAIN_3.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_3 = partial_df_test_3[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_3 = partial_df_test_3['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_3, reshaped_y_test_3 = get_frames(X_TEST_3, y_TEST_3) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "  logo = LeaveOneGroupOut()\n",
        "  split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "  groups = groups.to_numpy()\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "\n",
        "  for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "      # split data\n",
        "      X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "      y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "      X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train = pd.DataFrame(data = y_train)\n",
        "      y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "      reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "      reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "      y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "      X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "      y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "      reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "      reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_3, X_val_3 = X_TRAIN_3[train_ix, :], X_TRAIN_3[val_ix, :]\n",
        "      y_train_3, y_val_3 = y_TRAIN_3[train_ix], y_TRAIN_3[val_ix] \n",
        "\n",
        "      X_train_3 = pd.DataFrame(data = X_train_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_3 = pd.DataFrame(data = X_val_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_3 = pd.DataFrame(data = y_train_3)\n",
        "      y_val_3 = pd.DataFrame(data = y_val_3) \n",
        "\n",
        "      reshaped_X_train_3, reshaped_y_train_3 = get_frames(X_train_3, y_train_3) \n",
        "      reshaped_X_val_3, reshaped_y_val_3 = get_frames(X_val_3, y_val_3) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # defining some input variables\n",
        "      n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "      # getting the model\n",
        "      model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "      # fit model\n",
        "      history = model.fit([reshaped_X_train,reshaped_X_train_2,reshaped_X_train_3], reshaped_y_train,\n",
        "                epochs=50,\n",
        "                verbose=0,\n",
        "                callbacks=[lr_callback],\n",
        "                validation_data=([reshaped_X_val,reshaped_X_val_2,reshaped_X_val_3], reshaped_y_val)) # Chnage number of epochs!\n",
        "      \n",
        "      test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2,reshaped_X_test_3],reshaped_y_test, verbose=0)\n",
        "      acc_per_fold.append(test_scores[1] * 100)\n",
        "      loss_per_fold.append(test_scores[0])\n",
        "  mean_accuracy = np.mean(acc_per_fold)\n",
        "  mean_std = np.std(acc_per_fold)\n",
        "  mean_loss = np.mean(loss_per_fold)\n",
        "  print('Sensor:', sensor_position_number, 'Activity:', activity_number)\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmIOvBoEtiGr"
      },
      "outputs": [],
      "source": [
        "test_scores = []\n",
        "activity_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2,3]\n",
        "              ,[1,2,4]\n",
        "              ,[1,2,5]\n",
        "              ,[1,3,4]\n",
        "              ,[1,3,5]\n",
        "              ,[1,4,5]\n",
        "              ,[2,3,4]\n",
        "              ,[2,3,5]\n",
        "              ,[2,4,5]\n",
        "              ,[3,4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2abUgjk4BZKz",
        "outputId": "fd7e38b2-c090-445b-c68c-5b857d91170e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 2, 3] Activity: 2\n",
            "> Accuracy: 71.40729857396475 (+- 12.85812955350076)\n",
            "> Loss: 0.5711101123803779\n",
            "Sensor: [1, 2, 4] Activity: 2\n",
            "> Accuracy: 39.53834809834444 (+- 10.627737974328692)\n",
            "> Loss: 0.7861085111581827\n",
            "Sensor: [1, 2, 5] Activity: 2\n",
            "> Accuracy: 46.83544445264189 (+- 16.780486957888417)\n",
            "> Loss: 0.7775496440597728\n",
            "Sensor: [1, 3, 4] Activity: 2\n",
            "> Accuracy: 79.15115537522715 (+- 8.618743344904086)\n",
            "> Loss: 0.5439617784717415\n",
            "Sensor: [1, 3, 5] Activity: 2\n",
            "> Accuracy: 74.75800597215 (+- 8.984722102740344)\n",
            "> Loss: 0.5728801530373248\n",
            "Sensor: [1, 4, 5] Activity: 2\n",
            "> Accuracy: 51.005213622805435 (+- 9.937015648179354)\n",
            "> Loss: 0.6957460641860962\n",
            "Sensor: [2, 3, 4] Activity: 2\n",
            "> Accuracy: 52.27103667168678 (+- 10.123297372685856)\n",
            "> Loss: 0.781704501260685\n",
            "Sensor: [2, 3, 5] Activity: 2\n",
            "> Accuracy: 49.14370958186403 (+- 11.232878397398812)\n",
            "> Loss: 0.7863259141958212\n",
            "Sensor: [2, 4, 5] Activity: 2\n",
            "> Accuracy: 22.93373091688639 (+- 6.0363273319875645)\n",
            "> Loss: 1.0357690793049485\n",
            "Sensor: [3, 4, 5] Activity: 2\n",
            "> Accuracy: 54.653762073456484 (+- 8.837264500783865)\n",
            "> Loss: 0.7882235985767992\n",
            "Sensor: [1, 2, 3] Activity: 3\n",
            "> Accuracy: 51.74981525427179 (+- 11.704228758650066)\n",
            "> Loss: 0.8058021921145765\n",
            "Sensor: [1, 2, 4] Activity: 3\n",
            "> Accuracy: 38.4959056784835 (+- 9.672372837989059)\n",
            "> Loss: 0.9358529508868351\n",
            "Sensor: [1, 2, 5] Activity: 3\n",
            "> Accuracy: 39.38942762869823 (+- 8.747722782566441)\n",
            "> Loss: 0.9078055801270883\n",
            "Sensor: [1, 3, 4] Activity: 3\n",
            "> Accuracy: 51.52643481387368 (+- 13.143854057188449)\n",
            "> Loss: 0.6869336517551278\n",
            "Sensor: [1, 3, 5] Activity: 3\n",
            "> Accuracy: 57.48324831829795 (+- 9.588318652225851)\n",
            "> Loss: 0.6717867715449273\n",
            "Sensor: [1, 4, 5] Activity: 3\n",
            "> Accuracy: 45.04840038245237 (+- 13.751968317593809)\n",
            "> Loss: 0.8220345453370975\n",
            "Sensor: [2, 3, 4] Activity: 3\n",
            "> Accuracy: 30.752048462252073 (+- 9.12007872622014)\n",
            "> Loss: 0.9711698784103876\n",
            "Sensor: [2, 3, 5] Activity: 3\n",
            "> Accuracy: 32.98585333778888 (+- 10.313203327595641)\n",
            "> Loss: 0.9374472136738934\n",
            "Sensor: [2, 4, 5] Activity: 3\n",
            "> Accuracy: 22.635890185078487 (+- 10.084336779004735)\n",
            "> Loss: 1.0474064123781421\n",
            "Sensor: [3, 4, 5] Activity: 3\n",
            "> Accuracy: 43.559196808292896 (+- 9.051122751786195)\n",
            "> Loss: 0.8709601857994176\n",
            "Sensor: [1, 2, 3] Activity: 4\n",
            "> Accuracy: 46.01638260521466 (+- 8.462947834001639)\n",
            "> Loss: 0.7301795693892467\n",
            "Sensor: [1, 2, 4] Activity: 4\n",
            "> Accuracy: 46.686523624613315 (+- 7.507564480016067)\n",
            "> Loss: 0.7475312080564378\n",
            "Sensor: [1, 2, 5] Activity: 4\n",
            "> Accuracy: 42.665674942958205 (+- 10.399929093434237)\n",
            "> Loss: 0.7906219287763668\n",
            "Sensor: [1, 3, 4] Activity: 4\n",
            "> Accuracy: 61.05733642095252 (+- 7.903307169891851)\n",
            "> Loss: 0.6921847523013248\n",
            "Sensor: [1, 3, 5] Activity: 4\n",
            "> Accuracy: 64.78034450283533 (+- 6.101191490823754)\n",
            "> Loss: 0.7621339355842977\n",
            "Sensor: [1, 4, 5] Activity: 4\n",
            "> Accuracy: 57.48324812967566 (+- 9.858593730014118)\n",
            "> Loss: 0.7639647367634351\n",
            "Sensor: [2, 3, 4] Activity: 4\n",
            "> Accuracy: 24.348474128902712 (+- 6.533853136713138)\n",
            "> Loss: 0.8662941063506694\n",
            "Sensor: [2, 3, 5] Activity: 4\n",
            "> Accuracy: 16.976917619946637 (+- 8.474731466520279)\n",
            "> Loss: 0.9634489462345461\n",
            "Sensor: [2, 4, 5] Activity: 4\n",
            "> Accuracy: 9.009679897299296 (+- 6.053753359106927)\n",
            "> Loss: 0.9866037255601038\n",
            "Sensor: [3, 4, 5] Activity: 4\n",
            "> Accuracy: 32.68801251166983 (+- 11.903383839159387)\n",
            "> Loss: 0.9632701737971245\n",
            "Sensor: [1, 2, 3] Activity: 5\n",
            "> Accuracy: 68.27997199342221 (+- 10.729499913748457)\n",
            "> Loss: 0.5844101490853708\n",
            "Sensor: [1, 2, 4] Activity: 5\n",
            "> Accuracy: 63.961282561096965 (+- 12.072194680501562)\n",
            "> Loss: 0.6829110267041605\n",
            "Sensor: [1, 2, 5] Activity: 5\n",
            "> Accuracy: 35.443038889501665 (+- 11.269343602168696)\n",
            "> Loss: 0.8686499452289147\n",
            "Sensor: [1, 3, 4] Activity: 5\n",
            "> Accuracy: 85.25688844391063 (+- 6.3391795637169395)\n",
            "> Loss: 0.45927776754656924\n",
            "Sensor: [1, 3, 5] Activity: 5\n",
            "> Accuracy: 57.03648739977728 (+- 7.906113266342365)\n",
            "> Loss: 0.6962670185897923\n",
            "Sensor: [1, 4, 5] Activity: 5\n",
            "> Accuracy: 46.90990419704703 (+- 9.54369077612667)\n",
            "> Loss: 0.784735719614391\n",
            "Sensor: [2, 3, 4] Activity: 5\n",
            "> Accuracy: 51.07967400852638 (+- 10.528678337016427)\n",
            "> Loss: 0.7902974026112617\n",
            "Sensor: [2, 3, 5] Activity: 5\n",
            "> Accuracy: 25.688757011784784 (+- 7.497957605778598)\n",
            "> Loss: 1.052276091485084\n",
            "Sensor: [2, 4, 5] Activity: 5\n",
            "> Accuracy: 15.711094839852068 (+- 5.435082122629547)\n",
            "> Loss: 1.1852983885173556\n",
            "Sensor: [3, 4, 5] Activity: 5\n",
            "> Accuracy: 43.78257722039766 (+- 6.925195960311576)\n",
            "> Loss: 0.8627504630933834\n",
            "Sensor: [1, 2, 3] Activity: 6\n",
            "> Accuracy: 81.23603983770442 (+- 10.715538743700797)\n",
            "> Loss: 0.5418432219119012\n",
            "Sensor: [1, 2, 4] Activity: 6\n",
            "> Accuracy: 71.0349979657161 (+- 9.301859373236965)\n",
            "> Loss: 0.6319334620161902\n",
            "Sensor: [1, 2, 5] Activity: 6\n",
            "> Accuracy: 52.86671805985366 (+- 10.145180766359767)\n",
            "> Loss: 0.7480393263358104\n",
            "Sensor: [1, 3, 4] Activity: 6\n",
            "> Accuracy: 93.96872705296624 (+- 10.079386795032557)\n",
            "> Loss: 0.4700521566445314\n",
            "Sensor: [1, 3, 5] Activity: 6\n",
            "> Accuracy: 61.35517660575577 (+- 12.119864432811571)\n",
            "> Loss: 0.6651754115201249\n",
            "Sensor: [1, 4, 5] Activity: 6\n",
            "> Accuracy: 50.483992884430705 (+- 10.193159175521728)\n",
            "> Loss: 0.7168515226508998\n",
            "Sensor: [2, 3, 4] Activity: 6\n",
            "> Accuracy: 41.77215293615679 (+- 12.331646680144708)\n",
            "> Loss: 0.8038607315172123\n",
            "Sensor: [2, 3, 5] Activity: 6\n",
            "> Accuracy: 35.74087947984285 (+- 2.2486475011959937)\n",
            "> Loss: 0.9676902407332312\n",
            "Sensor: [2, 4, 5] Activity: 6\n",
            "> Accuracy: 24.869695230375363 (+- 5.765736883539558)\n",
            "> Loss: 1.1526027374629733\n",
            "Sensor: [3, 4, 5] Activity: 6\n",
            "> Accuracy: 51.52643545518948 (+- 4.971576046712465)\n",
            "> Loss: 0.8498498623884176\n",
            "Sensor: [1, 2, 3] Activity: 7\n",
            "> Accuracy: 75.72598804401446 (+- 10.521302198836173)\n",
            "> Loss: 0.5849421194082574\n",
            "Sensor: [1, 2, 4] Activity: 7\n",
            "> Accuracy: 64.48250363899183 (+- 10.228994679177278)\n",
            "> Loss: 0.696088039422337\n",
            "Sensor: [1, 2, 5] Activity: 7\n",
            "> Accuracy: 39.83618850949444 (+- 8.677085649621244)\n",
            "> Loss: 0.8398326326020157\n",
            "Sensor: [1, 3, 4] Activity: 7\n",
            "> Accuracy: 89.50111745279047 (+- 9.57558841004726)\n",
            "> Loss: 0.48209754009790057\n",
            "Sensor: [1, 3, 5] Activity: 7\n",
            "> Accuracy: 67.3864499300341 (+- 10.704150300141636)\n",
            "> Loss: 0.6386631791350208\n",
            "Sensor: [1, 4, 5] Activity: 7\n",
            "> Accuracy: 43.70811715533462 (+- 10.982306685823355)\n",
            "> Loss: 0.7952106398872182\n",
            "Sensor: [2, 3, 4] Activity: 7\n",
            "> Accuracy: 49.36708990908876 (+- 16.80590857235666)\n",
            "> Loss: 0.7519813527034808\n",
            "Sensor: [2, 3, 5] Activity: 7\n",
            "> Accuracy: 30.454207900204235 (+- 7.113187162522332)\n",
            "> Loss: 0.9719614816617362\n",
            "Sensor: [2, 4, 5] Activity: 7\n",
            "> Accuracy: 19.657483621488645 (+- 3.487725500766147)\n",
            "> Loss: 1.109305734875836\n",
            "Sensor: [3, 4, 5] Activity: 7\n",
            "> Accuracy: 50.11169197438638 (+- 6.475038784291472)\n",
            "> Loss: 0.7879840286472176\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(2, [1, 2, 3], 71.40729857396475),\n",
              " (2, [1, 2, 4], 39.53834809834444),\n",
              " (2, [1, 2, 5], 46.83544445264189),\n",
              " (2, [1, 3, 4], 79.15115537522715),\n",
              " (2, [1, 3, 5], 74.75800597215),\n",
              " (2, [1, 4, 5], 51.005213622805435),\n",
              " (2, [2, 3, 4], 52.27103667168678),\n",
              " (2, [2, 3, 5], 49.14370958186403),\n",
              " (2, [2, 4, 5], 22.93373091688639),\n",
              " (2, [3, 4, 5], 54.653762073456484),\n",
              " (3, [1, 2, 3], 51.74981525427179),\n",
              " (3, [1, 2, 4], 38.4959056784835),\n",
              " (3, [1, 2, 5], 39.38942762869823),\n",
              " (3, [1, 3, 4], 51.52643481387368),\n",
              " (3, [1, 3, 5], 57.48324831829795),\n",
              " (3, [1, 4, 5], 45.04840038245237),\n",
              " (3, [2, 3, 4], 30.752048462252073),\n",
              " (3, [2, 3, 5], 32.98585333778888),\n",
              " (3, [2, 4, 5], 22.635890185078487),\n",
              " (3, [3, 4, 5], 43.559196808292896),\n",
              " (4, [1, 2, 3], 46.01638260521466),\n",
              " (4, [1, 2, 4], 46.686523624613315),\n",
              " (4, [1, 2, 5], 42.665674942958205),\n",
              " (4, [1, 3, 4], 61.05733642095252),\n",
              " (4, [1, 3, 5], 64.78034450283533),\n",
              " (4, [1, 4, 5], 57.48324812967566),\n",
              " (4, [2, 3, 4], 24.348474128902712),\n",
              " (4, [2, 3, 5], 16.976917619946637),\n",
              " (4, [2, 4, 5], 9.009679897299296),\n",
              " (4, [3, 4, 5], 32.68801251166983),\n",
              " (5, [1, 2, 3], 68.27997199342221),\n",
              " (5, [1, 2, 4], 63.961282561096965),\n",
              " (5, [1, 2, 5], 35.443038889501665),\n",
              " (5, [1, 3, 4], 85.25688844391063),\n",
              " (5, [1, 3, 5], 57.03648739977728),\n",
              " (5, [1, 4, 5], 46.90990419704703),\n",
              " (5, [2, 3, 4], 51.07967400852638),\n",
              " (5, [2, 3, 5], 25.688757011784784),\n",
              " (5, [2, 4, 5], 15.711094839852068),\n",
              " (5, [3, 4, 5], 43.78257722039766),\n",
              " (6, [1, 2, 3], 81.23603983770442),\n",
              " (6, [1, 2, 4], 71.0349979657161),\n",
              " (6, [1, 2, 5], 52.86671805985366),\n",
              " (6, [1, 3, 4], 93.96872705296624),\n",
              " (6, [1, 3, 5], 61.35517660575577),\n",
              " (6, [1, 4, 5], 50.483992884430705),\n",
              " (6, [2, 3, 4], 41.77215293615679),\n",
              " (6, [2, 3, 5], 35.74087947984285),\n",
              " (6, [2, 4, 5], 24.869695230375363),\n",
              " (6, [3, 4, 5], 51.52643545518948),\n",
              " (7, [1, 2, 3], 75.72598804401446),\n",
              " (7, [1, 2, 4], 64.48250363899183),\n",
              " (7, [1, 2, 5], 39.83618850949444),\n",
              " (7, [1, 3, 4], 89.50111745279047),\n",
              " (7, [1, 3, 5], 67.3864499300341),\n",
              " (7, [1, 4, 5], 43.70811715533462),\n",
              " (7, [2, 3, 4], 49.36708990908876),\n",
              " (7, [2, 3, 5], 30.454207900204235),\n",
              " (7, [2, 4, 5], 19.657483621488645),\n",
              " (7, [3, 4, 5], 50.11169197438638)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2,3]\n",
        "              ,[1,2,4]\n",
        "              ,[1,2,5]\n",
        "              ,[1,3,4]\n",
        "              ,[1,3,5]\n",
        "              ,[1,4,5]\n",
        "              ,[2,3,4]\n",
        "              ,[2,3,5]\n",
        "              ,[2,4,5]\n",
        "              ,[3,4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0bBVmtY3gqN"
      },
      "source": [
        "## 4 Parallel Sensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAK9D-Mp3iU4"
      },
      "outputs": [],
      "source": [
        "# Multi-headed 1D CNN\n",
        "def cnn_model_creation(n_timesteps, n_features):\n",
        "    # head 1\n",
        "    inputs1 = Input(shape=(n_timesteps,n_features))\n",
        "    conv1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs1)\n",
        "    bn1 = BatchNormalization()(conv1)\n",
        "    pool1 = GlobalAveragePooling1D()(bn1) \n",
        "    flat1 = Flatten()(pool1)\n",
        "\n",
        "    # head 2\n",
        "    inputs2 = Input(shape=(n_timesteps,n_features))\n",
        "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs2)\n",
        "    bn2 = BatchNormalization()(conv2)\n",
        "    pool2 = GlobalAveragePooling1D()(bn2)\n",
        "    flat2 = Flatten()(pool2)\n",
        "\n",
        "    # head 3\n",
        "    inputs3 = Input(shape=(n_timesteps,n_features))\n",
        "    conv3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs3)\n",
        "    bn3 = BatchNormalization()(conv3)\n",
        "    pool3 = GlobalAveragePooling1D()(bn3)\n",
        "    flat3 = Flatten()(pool3)\n",
        "\n",
        "    # head 4\n",
        "    inputs4 = Input(shape=(n_timesteps,n_features))\n",
        "    conv4 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs4)\n",
        "    bn4 = BatchNormalization()(conv4)\n",
        "    pool4 = GlobalAveragePooling1D()(bn4)\n",
        "    flat4 = Flatten()(pool4)\n",
        "\n",
        "    # merge\n",
        "    merged = concatenate([flat1,flat2,flat3,flat4])\n",
        "\n",
        "    # interpretation\n",
        "    dense1 = Dense(16, activation='relu')(merged) #16\n",
        "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "    model = Model(inputs=[inputs1, inputs2, inputs3, inputs4], outputs=outputs)\n",
        "\n",
        "    # save a plot of the model\n",
        "    # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#GlobalAveragePooling1D - check results after changing to this!! *CHECK* #MaxPooling1D(pool_size=2)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def get_frames(X, Y):\n",
        "  \n",
        "  N_FEATURES = 6\n",
        "\n",
        "  frames = []\n",
        "  labels = []\n",
        "  for Subject_Trial_Number_Encoded in set(X.Subject_Trial_Number_Encoded):  #for each group\n",
        "    current_frame = X.loc[X.Subject_Trial_Number_Encoded == Subject_Trial_Number_Encoded]  #get the all the frames for that group\n",
        "    start_index = min(current_frame.index)\n",
        "    end_index = max(current_frame.index) + 1\n",
        "    frame_size = len(current_frame)\n",
        "\n",
        "    ax = X['x_accelero'].values[start_index: end_index] \n",
        "    ay = X['y_accelero'].values[start_index: end_index]\n",
        "    az = X['z_accelero'].values[start_index: end_index]\n",
        "    gx = X['x_gyro'].values[start_index: end_index] \n",
        "    gy = X['y_gyro'].values[start_index: end_index]\n",
        "    gz = X['z_gyro'].values[start_index: end_index]\n",
        "\n",
        "    # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(Y[start_index: end_index])[0][0]\n",
        "    \n",
        "    frames.append([ax, ay, az, gx, gy, gz])\n",
        "    labels.append(label)\n",
        "  # returns frames of samples, each sample(group) with three features, each feature with n timesteps 28*3*1729 i.e. groups/samples * features * timesteps\n",
        "\n",
        "  # As the frame size differes for each group, the frames are padded\n",
        "  padded_frames = []\n",
        "  for row in frames:\n",
        "    shape = np.shape(row)\n",
        "    padded_array = np.zeros((6, 3000)) \n",
        "    padded_array[:shape[0],:shape[1]] = row\n",
        "    padded_frames.append(padded_array)\n",
        "\n",
        "  # return exactly the same shape as above but padded so each group has same number of steps - might not need this for this experiment! *CHECK*\n",
        "\n",
        "  # Bring the segments into a better shape\n",
        "  reshaped_padded_frames = np.transpose(padded_frames, (0, 2, 1))\n",
        "  reshaped_labels = np.asarray(labels)\n",
        "  \n",
        "  # finally converts the  28*3*1729  -> 28*1729*3 i.e. groups/samples * timestep * features\n",
        "  return reshaped_padded_frames, reshaped_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFiKDxJl3iZR"
      },
      "outputs": [],
      "source": [
        "def get_scores(sensor_position_number, activity_number, full_gd_df): \n",
        "\n",
        "  partial_df = final_df.drop(columns=[0, \n",
        "                                    'subject_name', 'trial_number','timestamp', \n",
        "                                    'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                    'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "  partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "  partial_df_original = partial_df[partial_df[\"activity\"] == activity_number]\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 1\n",
        "  partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[0]]\n",
        "  partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN = partial_df_train['Gender Code']\n",
        "  X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "  y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 2\n",
        "  partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[1]]\n",
        "  partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "  X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "  y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 3\n",
        "  partial_df_3 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[2]]\n",
        "  partial_df_3 = partial_df_3.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_3 = partial_df_train_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_3 = partial_df_train_3['Gender Code']\n",
        "  X_TRAIN_3 = X_TRAIN_3.to_numpy() # for LOGO\n",
        "  y_TRAIN_3 = y_TRAIN_3.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_3 = partial_df_test_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_3 = partial_df_test_3['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_3, reshaped_y_test_3 = get_frames(X_TEST_3, y_TEST_3) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 4\n",
        "  partial_df_4 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[3]]\n",
        "  partial_df_4 = partial_df_4.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_4 = partial_df_4[partial_df_4['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_4 = partial_df_4[partial_df_4['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_4 = partial_df_train_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_4 = partial_df_train_4['Gender Code']\n",
        "  X_TRAIN_4 = X_TRAIN_4.to_numpy() # for LOGO\n",
        "  y_TRAIN_4 = y_TRAIN_4.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_4 = partial_df_test_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_4 = partial_df_test_4['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_4, reshaped_y_test_4 = get_frames(X_TEST_4, y_TEST_4) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "  logo = LeaveOneGroupOut()\n",
        "  split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "  groups = groups.to_numpy()\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "\n",
        "  for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "      # split data\n",
        "      X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "      y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "      X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train = pd.DataFrame(data = y_train)\n",
        "      y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "      reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "      reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "      y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "      X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro',  'Subject_Trial_Number_Encoded'])\n",
        "      X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "      y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "      reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "      reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_3, X_val_3 = X_TRAIN_3[train_ix, :], X_TRAIN_3[val_ix, :]\n",
        "      y_train_3, y_val_3 = y_TRAIN_3[train_ix], y_TRAIN_3[val_ix] \n",
        "\n",
        "      X_train_3 = pd.DataFrame(data = X_train_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_3 = pd.DataFrame(data = X_val_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_3 = pd.DataFrame(data = y_train_3)\n",
        "      y_val_3 = pd.DataFrame(data = y_val_3) \n",
        "\n",
        "      reshaped_X_train_3, reshaped_y_train_3 = get_frames(X_train_3, y_train_3) \n",
        "      reshaped_X_val_3, reshaped_y_val_3 = get_frames(X_val_3, y_val_3) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "       # split data\n",
        "      X_train_4, X_val_4 = X_TRAIN_4[train_ix, :], X_TRAIN_4[val_ix, :]\n",
        "      y_train_4, y_val_4 = y_TRAIN_4[train_ix], y_TRAIN_4[val_ix] \n",
        "\n",
        "      X_train_4 = pd.DataFrame(data = X_train_4, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_4 = pd.DataFrame(data = X_val_4, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train_4 = pd.DataFrame(data = y_train_4)\n",
        "      y_val_4 = pd.DataFrame(data = y_val_4) \n",
        "\n",
        "      reshaped_X_train_4, reshaped_y_train_4 = get_frames(X_train_4, y_train_4) \n",
        "      reshaped_X_val_4, reshaped_y_val_4 = get_frames(X_val_4, y_val_4) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # defining some input variables\n",
        "      n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "      # getting the model\n",
        "      model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "      # fit model\n",
        "      history = model.fit([reshaped_X_train,reshaped_X_train_2,reshaped_X_train_3,reshaped_X_train_4], reshaped_y_train,\n",
        "                epochs=50,\n",
        "                verbose=0,\n",
        "                callbacks=[lr_callback],\n",
        "                validation_data=([reshaped_X_val,reshaped_X_val_2,reshaped_X_val_3,reshaped_X_val_4], reshaped_y_val)) # Chnage number of epochs!\n",
        "      \n",
        "      test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2,reshaped_X_test_3,reshaped_X_test_4],reshaped_y_test, verbose=0)\n",
        "      acc_per_fold.append(test_scores[1] * 100)\n",
        "      loss_per_fold.append(test_scores[0])\n",
        "  mean_accuracy = np.mean(acc_per_fold)\n",
        "  mean_std = np.std(acc_per_fold)\n",
        "  mean_loss = np.mean(loss_per_fold)\n",
        "  print('Sensor:', sensor_position_number, 'Activity:', activity_number)\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8c3pTOO3idq",
        "outputId": "cc79a0f2-631f-4c77-dfbe-8ef76a2bb268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 2, 3, 4] Activity: 1\n",
            "> Accuracy: 71.3328383768661 (+- 12.464907004411053)\n",
            "> Loss: 0.5917135299761084\n",
            "Sensor: [1, 3, 4, 5] Activity: 1\n",
            "> Accuracy: 68.95011335234099 (+- 9.902361824324261)\n",
            "> Loss: 0.6394407402111005\n",
            "Sensor: [1, 4, 5, 2] Activity: 1\n",
            "> Accuracy: 42.21891402443753 (+- 10.370032020234849)\n",
            "> Loss: 0.816214836850951\n",
            "Sensor: [1, 5, 2, 3] Activity: 1\n",
            "> Accuracy: 61.429636916027796 (+- 11.376577473043486)\n",
            "> Loss: 0.6612128736097601\n",
            "Sensor: [2, 3, 4, 5] Activity: 1\n",
            "> Accuracy: 38.71928610001938 (+- 8.90912074212228)\n",
            "> Loss: 0.9103207822087445\n",
            "Sensor: [1, 2, 3, 4] Activity: 2\n",
            "> Accuracy: 61.28071655955496 (+- 12.887847789366393)\n",
            "> Loss: 0.6505535222307036\n",
            "Sensor: [1, 3, 4, 5] Activity: 2\n",
            "> Accuracy: 68.95011346551436 (+- 10.831842172313044)\n",
            "> Loss: 0.6316657703888567\n",
            "Sensor: [1, 4, 5, 2] Activity: 2\n",
            "> Accuracy: 37.527923436858984 (+- 10.308363754808715)\n",
            "> Loss: 0.8096437167517746\n",
            "Sensor: [1, 5, 2, 3] Activity: 2\n",
            "> Accuracy: 66.7907686550406 (+- 11.154619592540504)\n",
            "> Loss: 0.638167804555048\n",
            "Sensor: [2, 3, 4, 5] Activity: 2\n",
            "> Accuracy: 40.35740964397599 (+- 9.157692356472525)\n",
            "> Loss: 0.8915884283524526\n",
            "Sensor: [1, 2, 3, 4] Activity: 3\n",
            "> Accuracy: 42.7401350457457 (+- 10.903266940527063)\n",
            "> Loss: 0.8640665992905822\n",
            "Sensor: [1, 3, 4, 5] Activity: 3\n",
            "> Accuracy: 53.53685953194582 (+- 10.44726841280178)\n",
            "> Loss: 0.755920794945729\n",
            "Sensor: [1, 4, 5, 2] Activity: 3\n",
            "> Accuracy: 36.559941459305676 (+- 10.408455255405201)\n",
            "> Loss: 0.9583870934534676\n",
            "Sensor: [1, 5, 2, 3] Activity: 3\n",
            "> Accuracy: 48.02680702149114 (+- 11.32578070902982)\n",
            "> Loss: 0.8165506728087799\n",
            "Sensor: [2, 3, 4, 5] Activity: 3\n",
            "> Accuracy: 29.26284505785266 (+- 9.99209925728276)\n",
            "> Loss: 1.0230710257457782\n",
            "Sensor: [1, 2, 3, 4] Activity: 4\n",
            "> Accuracy: 43.8570376061186 (+- 8.516498746662315)\n",
            "> Loss: 0.7662106360061259\n",
            "Sensor: [1, 3, 4, 5] Activity: 4\n",
            "> Accuracy: 62.91884048075615 (+- 7.0882008771557485)\n",
            "> Loss: 0.7947113332869131\n",
            "Sensor: [1, 4, 5, 2] Activity: 4\n",
            "> Accuracy: 42.367834230012534 (+- 10.39619663184296)\n",
            "> Loss: 0.8171652132951761\n",
            "Sensor: [1, 5, 2, 3] Activity: 4\n",
            "> Accuracy: 47.13328492037858 (+- 9.613150981672465)\n",
            "> Loss: 0.8156278042853633\n",
            "Sensor: [2, 3, 4, 5] Activity: 4\n",
            "> Accuracy: 13.2539093635882 (+- 7.456433726014882)\n",
            "> Loss: 1.0022468853600417\n",
            "Sensor: [1, 2, 3, 4] Activity: 5\n",
            "> Accuracy: 68.35443211507193 (+- 12.671798101733117)\n",
            "> Loss: 0.5951051836526846\n",
            "Sensor: [1, 3, 4, 5] Activity: 5\n",
            "> Accuracy: 59.64259346829185 (+- 5.899764017718384)\n",
            "> Loss: 0.6719946046418781\n",
            "Sensor: [1, 4, 5, 2] Activity: 5\n",
            "> Accuracy: 39.6128083048742 (+- 11.297842814835747)\n",
            "> Loss: 0.8689057502565505\n",
            "Sensor: [1, 5, 2, 3] Activity: 5\n",
            "> Accuracy: 44.973940147629264 (+- 11.502589649759551)\n",
            "> Loss: 0.7786352815507334\n"
          ]
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2,3,4]\n",
        "               ,[1,3,4,5]\n",
        "               ,[1,4,5,2]\n",
        "               ,[1,5,2,3]\n",
        "               ,[2,3,4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVcxcVaB02zu",
        "outputId": "bf4d669b-fcf5-4a5b-e8d9-378ff4dd6dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 2, 3, 4] Activity: 5\n",
            "> Accuracy: 71.92851965185962 (+- 13.1349921088318)\n",
            "> Loss: 0.5696056251284443\n",
            "Sensor: [1, 3, 4, 5] Activity: 5\n",
            "> Accuracy: 60.16381450846225 (+- 7.827884764856527)\n",
            "> Loss: 0.6755475424513032\n",
            "Sensor: [1, 4, 5, 2] Activity: 5\n",
            "> Accuracy: 37.081162706960605 (+- 10.520776302811674)\n",
            "> Loss: 0.859238586093806\n",
            "Sensor: [1, 5, 2, 3] Activity: 5\n",
            "> Accuracy: 49.36709004112437 (+- 11.051253569814286)\n",
            "> Loss: 0.7498427697374851\n",
            "Sensor: [2, 3, 4, 5] Activity: 5\n",
            "> Accuracy: 28.14594254463534 (+- 8.19535536441449)\n",
            "> Loss: 1.0299418146097208\n",
            "Sensor: [1, 2, 3, 4] Activity: 6\n",
            "> Accuracy: 77.21519123149824 (+- 10.182818145141423)\n",
            "> Loss: 0.5479825750181947\n",
            "Sensor: [1, 3, 4, 5] Activity: 6\n",
            "> Accuracy: 60.7594952930378 (+- 12.993245416119251)\n",
            "> Loss: 0.6721772887284243\n",
            "Sensor: [1, 4, 5, 2] Activity: 6\n",
            "> Accuracy: 49.739391045479834 (+- 9.717551309873986)\n",
            "> Loss: 0.7787763642359383\n",
            "Sensor: [1, 5, 2, 3] Activity: 6\n",
            "> Accuracy: 51.74981510337395 (+- 11.66674629433175)\n",
            "> Loss: 0.7121481073053577\n",
            "Sensor: [2, 3, 4, 5] Activity: 6\n",
            "> Accuracy: 34.25167625463462 (+- 2.607169232808539)\n",
            "> Loss: 1.027424217024936\n",
            "Sensor: [1, 2, 3, 4] Activity: 7\n",
            "> Accuracy: 76.61950991878027 (+- 12.451110295891572)\n",
            "> Loss: 0.5703236487092851\n",
            "Sensor: [1, 3, 4, 5] Activity: 7\n",
            "> Accuracy: 66.86522892758816 (+- 9.41442683770778)\n",
            "> Loss: 0.646391221239597\n",
            "Sensor: [1, 4, 5, 2] Activity: 7\n",
            "> Accuracy: 42.96351559931719 (+- 11.514633599776525)\n",
            "> Loss: 0.8485916453071788\n",
            "Sensor: [1, 5, 2, 3] Activity: 7\n",
            "> Accuracy: 54.653761884834196 (+- 13.405725159065456)\n",
            "> Loss: 0.7439937350116198\n",
            "Sensor: [2, 3, 4, 5] Activity: 7\n",
            "> Accuracy: 30.454207654995255 (+- 9.3012641052291)\n",
            "> Loss: 0.9461902644060836\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(5, [1, 2, 3, 4], 71.92851965185962),\n",
              " (5, [1, 3, 4, 5], 60.16381450846225),\n",
              " (5, [1, 4, 5, 2], 37.081162706960605),\n",
              " (5, [1, 5, 2, 3], 49.36709004112437),\n",
              " (5, [2, 3, 4, 5], 28.14594254463534),\n",
              " (6, [1, 2, 3, 4], 77.21519123149824),\n",
              " (6, [1, 3, 4, 5], 60.7594952930378),\n",
              " (6, [1, 4, 5, 2], 49.739391045479834),\n",
              " (6, [1, 5, 2, 3], 51.74981510337395),\n",
              " (6, [2, 3, 4, 5], 34.25167625463462),\n",
              " (7, [1, 2, 3, 4], 76.61950991878027),\n",
              " (7, [1, 3, 4, 5], 66.86522892758816),\n",
              " (7, [1, 4, 5, 2], 42.96351559931719),\n",
              " (7, [1, 5, 2, 3], 54.653761884834196),\n",
              " (7, [2, 3, 4, 5], 30.454207654995255)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2,3,4]\n",
        "               ,[1,3,4,5]\n",
        "               ,[1,4,5,2]\n",
        "               ,[1,5,2,3]\n",
        "               ,[2,3,4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2esK0SeY3ird"
      },
      "source": [
        "## All 5 sensors in Parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNuY5asp3lgi"
      },
      "outputs": [],
      "source": [
        "# Multi-headed 1D CNN\n",
        "def cnn_model_creation(n_timesteps, n_features):\n",
        "    # head 1\n",
        "    inputs1 = Input(shape=(n_timesteps,n_features))\n",
        "    conv1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs1)\n",
        "    bn1 = BatchNormalization()(conv1)\n",
        "    pool1 = GlobalAveragePooling1D()(bn1) \n",
        "    flat1 = Flatten()(pool1)\n",
        "\n",
        "    # head 2\n",
        "    inputs2 = Input(shape=(n_timesteps,n_features))\n",
        "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs2)\n",
        "    bn2 = BatchNormalization()(conv2)\n",
        "    pool2 = GlobalAveragePooling1D()(bn2)\n",
        "    flat2 = Flatten()(pool2)\n",
        "\n",
        "    # head 3\n",
        "    inputs3 = Input(shape=(n_timesteps,n_features))\n",
        "    conv3 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs3)\n",
        "    bn3 = BatchNormalization()(conv3)\n",
        "    pool3 = GlobalAveragePooling1D()(bn3)\n",
        "    flat3 = Flatten()(pool3)\n",
        "\n",
        "    # head 4\n",
        "    inputs4 = Input(shape=(n_timesteps,n_features))\n",
        "    conv4 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs4)\n",
        "    bn4 = BatchNormalization()(conv4)\n",
        "    pool4 = GlobalAveragePooling1D()(bn4)\n",
        "    flat4 = Flatten()(pool4)\n",
        "\n",
        "    # head 5\n",
        "    inputs5 = Input(shape=(n_timesteps,n_features))\n",
        "    conv5 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(inputs5)\n",
        "    bn5 = BatchNormalization()(conv5)\n",
        "    pool5 = GlobalAveragePooling1D()(bn5)\n",
        "    flat5 = Flatten()(pool5)\n",
        "\n",
        "    # merge\n",
        "    merged = concatenate([flat1,flat2,flat3,flat4,flat5])\n",
        "\n",
        "    # interpretation\n",
        "    dense1 = Dense(16, activation='relu')(merged) #16\n",
        "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
        "    model = Model(inputs=[inputs1, inputs2, inputs3, inputs4,inputs5], outputs=outputs)\n",
        "\n",
        "    # save a plot of the model\n",
        "    # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "#GlobalAveragePooling1D - check results after changing to this!! *CHECK* #MaxPooling1D(pool_size=2)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def get_frames(X, Y):\n",
        "  \n",
        "  N_FEATURES = 6\n",
        "\n",
        "  frames = []\n",
        "  labels = []\n",
        "  for Subject_Trial_Number_Encoded in set(X.Subject_Trial_Number_Encoded):  #for each group\n",
        "    current_frame = X.loc[X.Subject_Trial_Number_Encoded == Subject_Trial_Number_Encoded]  #get the all the frames for that group\n",
        "    start_index = min(current_frame.index)\n",
        "    end_index = max(current_frame.index) + 1\n",
        "    frame_size = len(current_frame)\n",
        "\n",
        "    ax = X['x_accelero'].values[start_index: end_index] \n",
        "    ay = X['y_accelero'].values[start_index: end_index]\n",
        "    az = X['z_accelero'].values[start_index: end_index]\n",
        "    gx = X['x_gyro'].values[start_index: end_index] \n",
        "    gy = X['y_gyro'].values[start_index: end_index]\n",
        "    gz = X['z_gyro'].values[start_index: end_index]\n",
        "\n",
        "    # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(Y[start_index: end_index])[0][0]\n",
        "    \n",
        "    frames.append([ax, ay, az, gx, gy, gz])\n",
        "    labels.append(label)\n",
        "  # returns frames of samples, each sample(group) with three features, each feature with n timesteps 28*3*1729 i.e. groups/samples * features * timesteps\n",
        "\n",
        "  # As the frame size differes for each group, the frames are padded\n",
        "  padded_frames = []\n",
        "  for row in frames:\n",
        "    shape = np.shape(row)\n",
        "    padded_array = np.zeros((6, 3000)) \n",
        "    padded_array[:shape[0],:shape[1]] = row\n",
        "    padded_frames.append(padded_array)\n",
        "\n",
        "  # return exactly the same shape as above but padded so each group has same number of steps - might not need this for this experiment! *CHECK*\n",
        "\n",
        "  # Bring the segments into a better shape\n",
        "  reshaped_padded_frames = np.transpose(padded_frames, (0, 2, 1))\n",
        "  reshaped_labels = np.asarray(labels)\n",
        "  \n",
        "  # finally converts the  28*3*1729  -> 28*1729*3 i.e. groups/samples * timestep * features\n",
        "  return reshaped_padded_frames, reshaped_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mewRfG8O3lkQ"
      },
      "outputs": [],
      "source": [
        "def get_scores(sensor_position_number, activity_number, full_gd_df): \n",
        "\n",
        "  partial_df = final_df.drop(columns=[0,  \n",
        "                                    'subject_name', 'trial_number','timestamp', \n",
        "                                    'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI',\n",
        "                                    'Subject_Trial_Sensor_Activity_Number', 'Subject_Trial_Sensor_Number']) #DROP MORE COLUMNS\n",
        "  le = preprocessing.LabelEncoder()\n",
        "  partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "  partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "  partial_df_original = partial_df[partial_df[\"activity\"] == activity_number]\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 1\n",
        "  partial_df = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[0]]\n",
        "  partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN = partial_df_train['Gender Code']\n",
        "  X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "  y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 2\n",
        "  partial_df_2 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[1]]\n",
        "  partial_df_2 = partial_df_2.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_2 = partial_df_2[partial_df_2['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_2 = partial_df_train_2[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_2 = partial_df_train_2['Gender Code']\n",
        "  X_TRAIN_2 = X_TRAIN_2.to_numpy() # for LOGO\n",
        "  y_TRAIN_2 = y_TRAIN_2.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_2 = partial_df_test_2[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_2 = partial_df_test_2['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_2, reshaped_y_test_2 = get_frames(X_TEST_2, y_TEST_2) # convert test data to frames\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 3\n",
        "  partial_df_3 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[2]]\n",
        "  partial_df_3 = partial_df_3.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_3 = partial_df_3[partial_df_3['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_3 = partial_df_train_3[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_3 = partial_df_train_3['Gender Code']\n",
        "  X_TRAIN_3 = X_TRAIN_3.to_numpy() # for LOGO\n",
        "  y_TRAIN_3 = y_TRAIN_3.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_3 = partial_df_test_3[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_3 = partial_df_test_3['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_3, reshaped_y_test_3 = get_frames(X_TEST_3, y_TEST_3) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 4\n",
        "  partial_df_4 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[3]]\n",
        "  partial_df_4 = partial_df_4.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_4[['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_4 = partial_df_4[partial_df_4['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_4 = partial_df_4[partial_df_4['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_4 = partial_df_train_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_4 = partial_df_train_4['Gender Code']\n",
        "  X_TRAIN_4 = X_TRAIN_4.to_numpy() # for LOGO\n",
        "  y_TRAIN_4 = y_TRAIN_4.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_4 = partial_df_test_4[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_4 = partial_df_test_4['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_4, reshaped_y_test_4 = get_frames(X_TEST_4, y_TEST_4) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  # Get data for sensor 5\n",
        "  partial_df_5 = partial_df_original[partial_df_original[\"sensor_position\"] == sensor_position_number[4]]\n",
        "  partial_df_5 = partial_df_5.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) #this resets index each time for different sensor and activity combinations\n",
        "\n",
        "  # Standardise\n",
        "  scaler = StandardScaler()\n",
        "  partial_df_5[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df_5[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "  # Partition Train and Test Data\n",
        "  partial_df_train_5 = partial_df_5[partial_df_5['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) # check value!\n",
        "  partial_df_test_5 = partial_df_5[partial_df_5['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "  # Define TRAIN X and y variables\n",
        "  X_TRAIN_5 = partial_df_train_5[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']]\n",
        "  y_TRAIN_5 = partial_df_train_5['Gender Code']\n",
        "  X_TRAIN_5 = X_TRAIN_5.to_numpy() # for LOGO\n",
        "  y_TRAIN_5 = y_TRAIN_5.to_numpy() # for LOGO\n",
        "\n",
        "  # Define TEST X and y variables\n",
        "  X_TEST_5 = partial_df_test_5[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "  y_TEST_5 = partial_df_test_5['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "  reshaped_X_test_5, reshaped_y_test_5 = get_frames(X_TEST_5, y_TEST_5) # convert test data to frames\n",
        "  \n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "  logo = LeaveOneGroupOut()\n",
        "  split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "  groups = groups.to_numpy()\n",
        "\n",
        "  #-------------------------------------------------------------------------------------------\n",
        "\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "\n",
        "  for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "      # split data\n",
        "      X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "      y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "\n",
        "      X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      y_train = pd.DataFrame(data = y_train)\n",
        "      y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "      reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "      reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_2, X_val_2 = X_TRAIN_2[train_ix, :], X_TRAIN_2[val_ix, :]\n",
        "      y_train_2, y_val_2 = y_TRAIN_2[train_ix], y_TRAIN_2[val_ix] \n",
        "\n",
        "      X_train_2 = pd.DataFrame(data = X_train_2, columns = ['x_accelero', 'y_accelero', 'z_accelero','x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val_2 = pd.DataFrame(data = X_val_2, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      y_train_2 = pd.DataFrame(data = y_train_2)\n",
        "      y_val_2 = pd.DataFrame(data = y_val_2) \n",
        "\n",
        "      reshaped_X_train_2, reshaped_y_train_2 = get_frames(X_train_2, y_train_2) \n",
        "      reshaped_X_val_2, reshaped_y_val_2 = get_frames(X_val_2, y_val_2) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_3, X_val_3 = X_TRAIN_3[train_ix, :], X_TRAIN_3[val_ix, :]\n",
        "      y_train_3, y_val_3 = y_TRAIN_3[train_ix], y_TRAIN_3[val_ix] \n",
        "\n",
        "      X_train_3 = pd.DataFrame(data = X_train_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      X_val_3 = pd.DataFrame(data = X_val_3, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      y_train_3 = pd.DataFrame(data = y_train_3)\n",
        "      y_val_3 = pd.DataFrame(data = y_val_3) \n",
        "\n",
        "      reshaped_X_train_3, reshaped_y_train_3 = get_frames(X_train_3, y_train_3) \n",
        "      reshaped_X_val_3, reshaped_y_val_3 = get_frames(X_val_3, y_val_3) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "       # split data\n",
        "      X_train_4, X_val_4 = X_TRAIN_4[train_ix, :], X_TRAIN_4[val_ix, :]\n",
        "      y_train_4, y_val_4 = y_TRAIN_4[train_ix], y_TRAIN_4[val_ix] \n",
        "\n",
        "      X_train_4 = pd.DataFrame(data = X_train_4, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      X_val_4 = pd.DataFrame(data = X_val_4, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      y_train_4 = pd.DataFrame(data = y_train_4)\n",
        "      y_val_4 = pd.DataFrame(data = y_val_4) \n",
        "\n",
        "      reshaped_X_train_4, reshaped_y_train_4 = get_frames(X_train_4, y_train_4) \n",
        "      reshaped_X_val_4, reshaped_y_val_4 = get_frames(X_val_4, y_val_4) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # split data\n",
        "      X_train_5, X_val_5 = X_TRAIN_5[train_ix, :], X_TRAIN_5[val_ix, :]\n",
        "      y_train_5, y_val_5 = y_TRAIN_5[train_ix], y_TRAIN_5[val_ix] \n",
        "\n",
        "      X_train_5 = pd.DataFrame(data = X_train_5, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      X_val_5 = pd.DataFrame(data = X_val_5, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro','Subject_Trial_Number_Encoded'])\n",
        "      y_train_5 = pd.DataFrame(data = y_train_5)\n",
        "      y_val_5 = pd.DataFrame(data = y_val_5) \n",
        "\n",
        "      reshaped_X_train_5, reshaped_y_train_5 = get_frames(X_train_5, y_train_5) \n",
        "      reshaped_X_val_5, reshaped_y_val_5 = get_frames(X_val_5, y_val_5) \n",
        "\n",
        "      #-------------------------------------------------------------------------------------------\n",
        "\n",
        "      # defining some input variables\n",
        "      n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "      # getting the model\n",
        "      model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "      # fit model\n",
        "      history = model.fit([reshaped_X_train,reshaped_X_train_2,reshaped_X_train_3,reshaped_X_train_4,reshaped_X_train_5], reshaped_y_train,\n",
        "                epochs=50,\n",
        "                verbose=0,\n",
        "                callbacks=[lr_callback],\n",
        "                validation_data=([reshaped_X_val,reshaped_X_val_2,reshaped_X_val_3,reshaped_X_val_4,reshaped_X_val_5], reshaped_y_val)) # Chnage number of epochs!\n",
        "      \n",
        "      test_scores = model.evaluate([reshaped_X_test, reshaped_X_test_2,reshaped_X_test_3,reshaped_X_test_4,reshaped_X_test_5],reshaped_y_test, verbose=0)\n",
        "      acc_per_fold.append(test_scores[1] * 100)\n",
        "      loss_per_fold.append(test_scores[0])\n",
        "  mean_accuracy = np.mean(acc_per_fold)\n",
        "  mean_std = np.std(acc_per_fold)\n",
        "  mean_loss = np.mean(loss_per_fold)\n",
        "  print('Sensor:', sensor_position_number, 'Activity:', activity_number)\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  return mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUUTetRP3lwT",
        "outputId": "e390aedc-d35d-4ecb-a9aa-219db6ad0743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor: [1, 2, 3, 4, 5] Activity: 1\n",
            "> Accuracy: 64.70588415483886 (+- 11.501142904510653)\n",
            "> Loss: 0.6792124275919758\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 2\n",
            "> Accuracy: 56.81310671417019 (+- 11.420354548851746)\n",
            "> Loss: 0.7083135405673257\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 3\n",
            "> Accuracy: 44.005958056902585 (+- 12.411864338603614)\n",
            "> Loss: 0.8640396398834035\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 4\n",
            "> Accuracy: 46.9843646016302 (+- 8.90351854888274)\n",
            "> Loss: 0.8382881268670287\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 5\n",
            "> Accuracy: 53.31347878975204 (+- 12.878810857810723)\n",
            "> Loss: 0.7492911434626277\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 6\n",
            "> Accuracy: 50.63291293910787 (+- 10.481706728920882)\n",
            "> Loss: 0.726295788454104\n",
            "Sensor: [1, 2, 3, 4, 5] Activity: 7\n",
            "> Accuracy: 53.239018573791164 (+- 16.818440124447147)\n",
            "> Loss: 0.7352469571029083\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(1, [1, 2, 3, 4, 5], 64.70588415483886),\n",
              " (2, [1, 2, 3, 4, 5], 56.81310671417019),\n",
              " (3, [1, 2, 3, 4, 5], 44.005958056902585),\n",
              " (4, [1, 2, 3, 4, 5], 46.9843646016302),\n",
              " (5, [1, 2, 3, 4, 5], 53.31347878975204),\n",
              " (6, [1, 2, 3, 4, 5], 50.63291293910787),\n",
              " (7, [1, 2, 3, 4, 5], 53.239018573791164)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_scores = []\n",
        "activity_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [\n",
        "               [1,2,3,4,5]\n",
        "               ]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, final_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))\n",
        "\n",
        "test_scores"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}