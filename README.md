# Human-Biometric-Recognition

This code implements gender recognition utilizing wearable sensor data across various activities and sensor placements. As part of our comprehensive research, we explored multiple approaches to identify the most effective combinations of sensors, activities, and model architectures for optimal results. Our experiments included the use of autoencoders in place of 1D Convolutional Neural Networks (CNNs), the omission of certain signal features in different directions, and the exclusion of gyroscope readings altogether.  Ultimately, we pursued two distinct strategies with the 1D CNN model, incorporating both accelerometer and gyroscope data in all three directions. The first method evaluated gender recognition accuracy for each sensor and activity using a 1D CNN. The second fuses data from multiple sensors for each activity using a multi-head 1D CNN.

Citation:
Supriya Roy, Bahareh Nakisa, Pubudu N. Pathirana, and Richard Dazeley, 2024. "A Wearable Multi-Sensor Fusion Approach for Gender Recognition based on Deep Learning," in Proceedings of the 2023 10th International Conference on Bioinformatics Research and Applications (ICBRA '23), Association for Computing Machinery, New York, NY, USA, pp. 114â€“119. https://doi.org/10.1145/3632047.3632065
