{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVB1XA8LDc86"
      },
      "source": [
        "\n",
        "# **Deep-Learning Based Human Physical Activity Recognition with Wearable Sensor Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D7_SgC2lxMK"
      },
      "source": [
        "The following code implements gender recognition utilising BioKinâ„¢ wearable sensor data for multiple activities and sensor placements. This particular example utilises all the six measured signals (accelero x, y, z and gyro x, y, z) and applies end-to-end deep learning with 1D CNN, taking in one sensor and activity combination at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw-FfysZMuZh"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC3orRvYnMqI",
        "outputId": "37fef19b-2d43-4734-be44-920f6d9d1a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "%matplotlib inline\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import scipy.io\n",
        "import glob\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling1D\n",
        "from keras.layers import Input, Add, Permute, Reshape, multiply\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot, image\n",
        "from scipy import stats\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJonGs4rZmOH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/HAR Research Project/Datasets/Research Dataset')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUrRXDz757hP"
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The following section reads the accelerometer and gyroscope sensor readings of several different activities conducted by test subjects into a Pandas data frame.\n",
        "The dataset consists of 135 subject-trial groups, with 45 subjects undergoing three trials each for seven different activities simultaneously measured by five sensors.\n",
        "The dataset has been divided into seven activity folders, whereby each folder consists of .CSV files named as per the following convention:\n",
        "'activityNumber_subjectName_trialNumber_startTimestamp_sensorNumber'\n",
        "'''\n",
        "\n",
        "archive_ = globals()\n",
        "files_ = globals()\n",
        "df_ = globals()\n",
        "\n",
        "archive = []\n",
        "all_dfs = []\n",
        "\n",
        "# Loop through all the seven activity folders\n",
        "for i in range(1,8):\n",
        "  folder_path = f\"{i}\" + '.zip'\n",
        "  # Read ZIP folder\n",
        "  archive_[f\"{i}\"] = ZipFile(folder_path, 'r')\n",
        "  archive.append(archive_[f\"{i}\"])\n",
        "  # Read names of the files in ZIP folder\n",
        "  files_[f\"{i}\"] = archive_[f\"{i}\"].namelist()\n",
        "  dfs = []\n",
        "  # Loop through all the files in the activity ZIP folder\n",
        "  for file in files_[f\"{i}\"][1:]: # skip .DS_Store\n",
        "    # Read file\n",
        "    frame = pd.read_csv(archive[i-1].open(file), header=None)\n",
        "    # Add filename as column\n",
        "    frame['filename'] = os.path.basename(file)\n",
        "    # Append all dataframes from within the activity\n",
        "    dfs.append(frame)\n",
        "  # Concatenate all dataframes from within the activity\n",
        "  df_[f\"{i}\"] = pd.concat(dfs,ignore_index=True)\n",
        "  # Append all dataframes from all activites\n",
        "  all_dfs.append(df_[f\"{i}\"])\n",
        "# Concatenate all dataframes from all activities\n",
        "raw_df = pd.concat(all_dfs)"
      ],
      "metadata": {
        "id": "XMS8P8lPCzsu"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "nLUBxcJwYwWP"
      },
      "outputs": [],
      "source": [
        "# Read the subject characteristics into a Pandas data frame.\n",
        "gender_df = pd.read_csv('subject_chars_sheet1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_MBTqaKbDTi"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwvxNcmCnJD_"
      },
      "source": [
        "Note: The data is not fully complete for all subjects and trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "cMVMDnbKYadU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "cc403e9e-9e2a-40fc-c9b5-54370d4fd490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         x_accelero  y_accelero  z_accelero    x_gyro    y_gyro    z_gyro  \\\n",
              "0         -0.995988   -9.761160   -0.081403 -1.251221  2.136230  0.091553   \n",
              "1         -1.065420   -9.674969   -0.124498 -0.671387  0.579834  1.220703   \n",
              "2         -1.065420   -9.732430   -0.167594 -1.678467 -0.610352  0.732422   \n",
              "3         -1.079785   -9.758766   -0.102951 -1.159668  0.305176  0.183105   \n",
              "4         -1.082179   -9.773131   -0.213084 -0.183105  0.000000 -0.152588   \n",
              "...             ...         ...         ...       ...       ...       ...   \n",
              "4582020   -0.217872   -9.279926   -1.654393 -2.685547  5.126953 -1.892090   \n",
              "4582021    0.196325   -9.339781   -1.697489 -4.241943 -0.488281 -0.335693   \n",
              "4582022    0.548272   -9.232042   -1.563414 -4.608154 -0.976562  2.197266   \n",
              "4582023    0.591368   -9.188946   -1.699883 -4.943848 -0.061035  5.218506   \n",
              "4582024    0.323217   -9.181763   -1.838747 -5.462646  3.967285  7.080078   \n",
              "\n",
              "         activity subject_name trial_number   timestamp  sensor_position  Age  \\\n",
              "0               1        amala          1st  1567760697                1   45   \n",
              "1               1        amala          1st  1567760697                1   45   \n",
              "2               1        amala          1st  1567760697                1   45   \n",
              "3               1        amala          1st  1567760697                1   45   \n",
              "4               1        amala          1st  1567760697                1   45   \n",
              "...           ...          ...          ...         ...              ...  ...   \n",
              "4582020         7          van          3rd  1566546471                5   36   \n",
              "4582021         7          van          3rd  1566546471                5   36   \n",
              "4582022         7          van          3rd  1566546471                5   36   \n",
              "4582023         7          van          3rd  1566546471                5   36   \n",
              "4582024         7          van          3rd  1566546471                5   36   \n",
              "\n",
              "         Age Group  Gender  Gender Code  Weight  Height   BMI  \\\n",
              "0                3  Female            0    62.7   168.0  22.2   \n",
              "1                3  Female            0    62.7   168.0  22.2   \n",
              "2                3  Female            0    62.7   168.0  22.2   \n",
              "3                3  Female            0    62.7   168.0  22.2   \n",
              "4                3  Female            0    62.7   168.0  22.2   \n",
              "...            ...     ...          ...     ...     ...   ...   \n",
              "4582020          2    Male            1    79.0   173.0  26.4   \n",
              "4582021          2    Male            1    79.0   173.0  26.4   \n",
              "4582022          2    Male            1    79.0   173.0  26.4   \n",
              "4582023          2    Male            1    79.0   173.0  26.4   \n",
              "4582024          2    Male            1    79.0   173.0  26.4   \n",
              "\n",
              "        Subject_Trial_Number  \n",
              "0                   amala1st  \n",
              "1                   amala1st  \n",
              "2                   amala1st  \n",
              "3                   amala1st  \n",
              "4                   amala1st  \n",
              "...                      ...  \n",
              "4582020               van3rd  \n",
              "4582021               van3rd  \n",
              "4582022               van3rd  \n",
              "4582023               van3rd  \n",
              "4582024               van3rd  \n",
              "\n",
              "[4582025 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5677d042-5df7-4255-82ad-4882329f0d3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_accelero</th>\n",
              "      <th>y_accelero</th>\n",
              "      <th>z_accelero</th>\n",
              "      <th>x_gyro</th>\n",
              "      <th>y_gyro</th>\n",
              "      <th>z_gyro</th>\n",
              "      <th>activity</th>\n",
              "      <th>subject_name</th>\n",
              "      <th>trial_number</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_position</th>\n",
              "      <th>Age</th>\n",
              "      <th>Age Group</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Gender Code</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Subject_Trial_Number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.995988</td>\n",
              "      <td>-9.761160</td>\n",
              "      <td>-0.081403</td>\n",
              "      <td>-1.251221</td>\n",
              "      <td>2.136230</td>\n",
              "      <td>0.091553</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.065420</td>\n",
              "      <td>-9.674969</td>\n",
              "      <td>-0.124498</td>\n",
              "      <td>-0.671387</td>\n",
              "      <td>0.579834</td>\n",
              "      <td>1.220703</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.065420</td>\n",
              "      <td>-9.732430</td>\n",
              "      <td>-0.167594</td>\n",
              "      <td>-1.678467</td>\n",
              "      <td>-0.610352</td>\n",
              "      <td>0.732422</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.079785</td>\n",
              "      <td>-9.758766</td>\n",
              "      <td>-0.102951</td>\n",
              "      <td>-1.159668</td>\n",
              "      <td>0.305176</td>\n",
              "      <td>0.183105</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.082179</td>\n",
              "      <td>-9.773131</td>\n",
              "      <td>-0.213084</td>\n",
              "      <td>-0.183105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.152588</td>\n",
              "      <td>1</td>\n",
              "      <td>amala</td>\n",
              "      <td>1st</td>\n",
              "      <td>1567760697</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>62.7</td>\n",
              "      <td>168.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>amala1st</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582020</th>\n",
              "      <td>-0.217872</td>\n",
              "      <td>-9.279926</td>\n",
              "      <td>-1.654393</td>\n",
              "      <td>-2.685547</td>\n",
              "      <td>5.126953</td>\n",
              "      <td>-1.892090</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582021</th>\n",
              "      <td>0.196325</td>\n",
              "      <td>-9.339781</td>\n",
              "      <td>-1.697489</td>\n",
              "      <td>-4.241943</td>\n",
              "      <td>-0.488281</td>\n",
              "      <td>-0.335693</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582022</th>\n",
              "      <td>0.548272</td>\n",
              "      <td>-9.232042</td>\n",
              "      <td>-1.563414</td>\n",
              "      <td>-4.608154</td>\n",
              "      <td>-0.976562</td>\n",
              "      <td>2.197266</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582023</th>\n",
              "      <td>0.591368</td>\n",
              "      <td>-9.188946</td>\n",
              "      <td>-1.699883</td>\n",
              "      <td>-4.943848</td>\n",
              "      <td>-0.061035</td>\n",
              "      <td>5.218506</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4582024</th>\n",
              "      <td>0.323217</td>\n",
              "      <td>-9.181763</td>\n",
              "      <td>-1.838747</td>\n",
              "      <td>-5.462646</td>\n",
              "      <td>3.967285</td>\n",
              "      <td>7.080078</td>\n",
              "      <td>7</td>\n",
              "      <td>van</td>\n",
              "      <td>3rd</td>\n",
              "      <td>1566546471</td>\n",
              "      <td>5</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>79.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>van3rd</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4582025 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5677d042-5df7-4255-82ad-4882329f0d3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5677d042-5df7-4255-82ad-4882329f0d3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5677d042-5df7-4255-82ad-4882329f0d3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "# Rename columns\n",
        "full_df = raw_df.rename(columns={0: 'x_accelero', 1: 'y_accelero', 2: 'z_accelero', 3 : 'x_gyro', 4: 'y_gyro', 5: 'z_gyro'}, errors=\"raise\")\n",
        "\n",
        "# Split the filename into seperate columns\n",
        "full_df[['activity','subject_name', 'trial_number', 'timestamp', 'sensor_position']] = full_df['filename'].str.split('_',expand=True)\n",
        "full_df[['sensor_position','file_type']] = full_df['sensor_position'].str.split('.',expand=True)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "full_df.drop(columns=['filename', 'file_type'], inplace=True)\n",
        "\n",
        "# Merge the sensor readings' dataframe with the subject characteristcs' dataframe\n",
        "full_gd_df = full_df.merge(gender_df, on='subject_name', how='left')\n",
        "\n",
        "# Convert datatype for sensor readings\n",
        "full_gd_df['x_accelero'] = pd.to_numeric(full_gd_df['x_accelero'])\n",
        "full_gd_df['y_accelero'] = pd.to_numeric(full_gd_df['y_accelero'])\n",
        "full_gd_df['z_accelero'] = pd.to_numeric(full_gd_df['z_accelero'])\n",
        "full_gd_df['x_gyro'] = pd.to_numeric(full_gd_df['x_gyro'])\n",
        "\n",
        "full_gd_df['y_gyro'] = full_gd_df['y_gyro'].astype('string')\n",
        "full_gd_df['y_gyro'] = full_gd_df['y_gyro'].apply(lambda x: x[:-2] if x[-2:] == \".1\" else x)\n",
        "full_gd_df['y_gyro'] = pd.to_numeric(full_gd_df['y_gyro'])\n",
        "\n",
        "full_gd_df['z_gyro'] = full_gd_df['z_gyro'].astype('string')\n",
        "full_gd_df['z_gyro'] = full_gd_df['z_gyro'].apply(lambda x: x[:-2] if x[-2:] == \".1\" else x)\n",
        "full_gd_df['z_gyro'] = pd.to_numeric(full_gd_df['z_gyro'])\n",
        "\n",
        "full_gd_df['sensor_position'] = pd.to_numeric(full_gd_df['sensor_position'])\n",
        "full_gd_df['activity'] = pd.to_numeric(full_gd_df['activity'])\n",
        "full_gd_df['Gender Code'] = pd.to_numeric(full_gd_df['Gender Code'])\n",
        "\n",
        "# Merge subject name and trial number\n",
        "full_gd_df[\"Subject_Trial_Number\"] = full_gd_df[\"subject_name\"] + full_gd_df[\"trial_number\"]\n",
        "\n",
        "full_gd_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkmhndvdJc-6"
      },
      "source": [
        "## Function Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P9UOY_tJ4OQ"
      },
      "source": [
        "### Reshaping Signal Sequences into Frames with the Sliding Window Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "Ppsm7536Y30N"
      },
      "outputs": [],
      "source": [
        "def get_frames(X, Y):\n",
        "  '''\n",
        "  Returns frames of samples, each sample(group) with six features, each feature with n timesteps i.e. groups/samples * features * timesteps\n",
        "  '''\n",
        "  \n",
        "  N_FEATURES = 6\n",
        "  frames = []\n",
        "  labels = []\n",
        "\n",
        "  # Loop through each group\n",
        "  for Subject_Trial_Number_Encoded in set(X.Subject_Trial_Number_Encoded):\n",
        "    # Obtain the all the frames for that group\n",
        "    current_frame = X.loc[X.Subject_Trial_Number_Encoded == Subject_Trial_Number_Encoded]  \n",
        "    start_index = min(current_frame.index)\n",
        "    end_index = max(current_frame.index) + 1\n",
        "    frame_size = len(current_frame)\n",
        "\n",
        "    ax = X['x_accelero'].values[start_index: end_index] \n",
        "    ay = X['y_accelero'].values[start_index: end_index]\n",
        "    az = X['z_accelero'].values[start_index: end_index]\n",
        "    gx = X['x_gyro'].values[start_index: end_index] \n",
        "    gy = X['y_gyro'].values[start_index: end_index]\n",
        "    gz = X['z_gyro'].values[start_index: end_index]\n",
        "\n",
        "    # Retrieve the most often used label in this segment\n",
        "    label = stats.mode(Y[start_index: end_index])[0][0]\n",
        "    \n",
        "    frames.append([ax, ay, az, gx, gy, gz])\n",
        "    labels.append(label)\n",
        "\n",
        "  # Since the frame sizes differ for each group, the frames are padded with 0s. \n",
        "  # Returns exactly the same shape as above but padded so each group has same number of steps. \n",
        "  padded_frames = []\n",
        "  for row in frames:\n",
        "    shape = np.shape(row)\n",
        "    padded_array = np.zeros((6, 3000)) # 3000 is max number of steps for any group\n",
        "    padded_array[:shape[0],:shape[1]] = row\n",
        "    padded_frames.append(padded_array)\n",
        "\n",
        "  # Bring the segments into a better shape i.e. converts the  groups/samples * features * timesteps  ->  groups/samples * timestep * features\n",
        "  reshaped_padded_frames = np.transpose(padded_frames, (0, 2, 1))\n",
        "  reshaped_labels = np.asarray(labels)\n",
        "  \n",
        "  return reshaped_padded_frames, reshaped_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnQRy1yAJrYy"
      },
      "source": [
        "### Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "jaKObCBKXB4o"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "  ''''\n",
        "  Returns the initial learning rate for the first ten epochs and then decreases it exponentially afterward.\n",
        "  '''\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "# Create a callback for the Learning Rate Scheduler\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeShXRlXJpPn"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "5uYlJ05cJlXQ"
      },
      "outputs": [],
      "source": [
        "def cnn_model_creation(n_timesteps, n_features):\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='same', input_shape=(n_timesteps,n_features)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(GlobalAveragePooling1D())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                 optimizer='Adam',\n",
        "                 metrics=['accuracy'])\n",
        "    \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za-GrQzmJtxC"
      },
      "source": [
        "### Autoencoder Model - not utilised as CNN returns better performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMtdTbijoX_l"
      },
      "outputs": [],
      "source": [
        "def squeeze_excite_block(inputs):\n",
        "    ''' \n",
        "    Create a squeeze-excite block\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "        k: width factor\n",
        "    Returns: a keras tensor\n",
        "    '''\n",
        "    filters = inputs.shape[-1] # channel_axis = -1 for TF\n",
        "\n",
        "    se = GlobalAveragePooling1D()(inputs)\n",
        "    se = Reshape((1, filters))(se)\n",
        "    se = Dense(filters // 16,  activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = multiply([inputs, se])\n",
        "    return se\n",
        "\n",
        "def SOTA_model_creation_(n_timesteps, n_features):\n",
        "    input_ = Input(shape=(n_timesteps, n_features))\n",
        "\n",
        "    # RNN\n",
        "    r_layer1 = LSTM(8)(input_)\n",
        "\n",
        "    # CNN\n",
        "    c_layer1 = Conv1D(64, 8, activation='relu', padding='same')(input_)\n",
        "    c_layer1 = BatchNormalization()(c_layer1)\n",
        "    c_layer1 = squeeze_excite_block(c_layer1)\n",
        "\n",
        "    c_layer2 = Conv1D(128, 5, activation='relu', padding='same')(c_layer1)\n",
        "    c_layer2 = BatchNormalization()(c_layer2)\n",
        "    c_layer2 = squeeze_excite_block(c_layer2)\n",
        "\n",
        "    c_layer3 = Conv1D(64, 3, activation='relu', padding='same')(c_layer2)\n",
        "    c_layer3 = BatchNormalization()(c_layer3)\n",
        "\n",
        "    c_pool = GlobalAveragePooling1D()(c_layer3)\n",
        "\n",
        "    merge = Concatenate()([r_layer1, c_pool])\n",
        "    output = Dense(1, activation='sigmoid')(merge)\n",
        "    model = Model(inputs=[input_], outputs=output)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m-yFvVoJybj"
      },
      "source": [
        "### Plot Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "xvw_GF_A15Ok"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    '''\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "    \n",
        "    Args:\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "       class_names (array, shape = [n]): String names of the integer classes\n",
        "    '''\n",
        "    \n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    # Normalize the confusion matrix.\n",
        "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    \n",
        "    # Use white text if squares are dark; otherwise black\n",
        "    threshold = cm.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_qSLvK0ZKrd"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ATZKrkKHZBYN"
      },
      "outputs": [],
      "source": [
        "def get_scores(sensor_position_number, activity_number, full_gd_df): \n",
        "   \n",
        "    # Drop unrequired columns\n",
        "    partial_df = full_gd_df.drop(columns=['subject_name', 'trial_number','timestamp', 'Age', 'Age Group', 'Gender', 'Weight', 'Height', 'BMI'])\n",
        "    \n",
        "    # Encode the Subject_Trial_Number\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    partial_df['Subject_Trial_Number_Encoded'] = le.fit_transform(partial_df['Subject_Trial_Number'])\n",
        "    partial_df = partial_df.drop(columns=['Subject_Trial_Number'])\n",
        "    \n",
        "    # Extract data for specified sensor and activity\n",
        "    # partial_df = partial_df[partial_df[\"sensor_position\"] == 1]\n",
        "    partial_df = partial_df[partial_df[\"sensor_position\"] == sensor_position_number]\n",
        "    # partial_df = partial_df[partial_df[\"activity\"] == 1]\n",
        "    partial_df = partial_df[partial_df[\"activity\"] == activity_number]\n",
        "    partial_df = partial_df.drop(columns=['sensor_position', 'activity']).reset_index(drop=True) # this resets index each time for different sensor and activity combinations\n",
        "\n",
        "    # Standardise the sensor readings\n",
        "    scaler = StandardScaler()\n",
        "    partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']] = scaler.fit_transform(partial_df[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro']])\n",
        "\n",
        "    # Partition Train+Val (i.e. partial_df_train) and Test Data (i.e. partial_df_test)\n",
        "    partial_df_train = partial_df[partial_df['Subject_Trial_Number_Encoded'] < 79].reset_index(drop=True) \n",
        "    partial_df_test = partial_df[partial_df['Subject_Trial_Number_Encoded'] >= 79].reset_index(drop=True) \n",
        "\n",
        "    # Define Train X and y variables\n",
        "    X_TRAIN = partial_df_train[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']]\n",
        "    y_TRAIN = partial_df_train['Gender Code']\n",
        "    X_TRAIN = X_TRAIN.to_numpy() # for LOGO\n",
        "    y_TRAIN = y_TRAIN.to_numpy() # for LOGO\n",
        "\n",
        "    # Define Test X and y variables\n",
        "    X_TEST = partial_df_test[['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded']].reset_index(drop=True)\n",
        "    y_TEST = partial_df_test['Gender Code'].reset_index(drop=True)\n",
        "\n",
        "    # Convert Test data to frames\n",
        "    reshaped_X_test, reshaped_y_test = get_frames(X_TEST, y_TEST) \n",
        "    \n",
        "    # Obtain groups for LOGO\n",
        "    groups = partial_df_train['Subject_Trial_Number_Encoded']\n",
        "    logo = LeaveOneGroupOut()\n",
        "    split_number = logo.get_n_splits(X_TRAIN, y_TRAIN, groups)\n",
        "    groups = groups.to_numpy()\n",
        "\n",
        "    # Initialise lists\n",
        "    acc_per_fold = []\n",
        "    loss_per_fold = []\n",
        "    train_acc_per_fold = []\n",
        "    train_loss_per_fold = []\n",
        "    val_acc_per_fold = []\n",
        "    val_loss_per_fold = []\n",
        "    cm_holder_per_fold = []\t\n",
        "    y_true, y_pred, y_pred_prob = list(), list(),list()\n",
        "\n",
        "    # Train model with leave-one-group-out cross validation\n",
        "    for train_ix, val_ix in logo.split(X_TRAIN, y_TRAIN, groups):\n",
        "      # Split data for training and validation\n",
        "      X_train, X_val = X_TRAIN[train_ix, :], X_TRAIN[val_ix, :]\n",
        "      y_train, y_val = y_TRAIN[train_ix], y_TRAIN[val_ix] \n",
        "      \n",
        "      X_train = pd.DataFrame(data = X_train, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      X_val = pd.DataFrame(data = X_val, columns = ['x_accelero', 'y_accelero', 'z_accelero', 'x_gyro', 'y_gyro', 'z_gyro', 'Subject_Trial_Number_Encoded'])\n",
        "      y_train = pd.DataFrame(data = y_train)\n",
        "      y_val = pd.DataFrame(data = y_val) \n",
        "\n",
        "      # Convert train and validation data to frames\n",
        "      reshaped_X_train, reshaped_y_train = get_frames(X_train, y_train) \n",
        "      reshaped_X_val, reshaped_y_val = get_frames(X_val, y_val) \n",
        "      \n",
        "      # Define input variables\n",
        "      n_timesteps, n_features, n_outputs = reshaped_X_train.shape[1], reshaped_X_val.shape[2], reshaped_y_train.shape[1]\n",
        "\n",
        "      # Obtain the model\n",
        "      model = cnn_model_creation(n_timesteps, n_features)\n",
        "\n",
        "      # Save model summary\n",
        "      #model.summary()\n",
        "      #plot_model(model, to_file='model_plot_1.png', show_shapes=True, show_layer_names=True)  \n",
        "      \n",
        "      # Train model\n",
        "      history = model.fit(reshaped_X_train, reshaped_y_train,\n",
        "                epochs=50,\n",
        "                verbose=0,\n",
        "                callbacks=[lr_callback],\n",
        "                validation_data=(reshaped_X_val, reshaped_y_val)) \n",
        "      \n",
        "      # Evaluate on Test data\n",
        "      test_scores = model.evaluate(reshaped_X_test,reshaped_y_test, verbose=0)\n",
        "      acc_per_fold.append(test_scores[1] * 100)\n",
        "      loss_per_fold.append(test_scores[0])\n",
        "\n",
        "      # For plotting the Confusion Matrix\n",
        "      ## Utilise the model to predict the values from the test data.\t\n",
        "      predictions_ = model.predict(reshaped_X_test)\t\n",
        "\n",
        "      ## Select the class with the highest probability from the test predictions\t\n",
        "      predictions = np.where(predictions_ > 0.5, 1, 0)\t\n",
        "\n",
        "      ## Calculate the confusion matrix using sklearn.metrics\t\n",
        "      cm = metrics.confusion_matrix(reshaped_y_test, predictions)\t\n",
        "\n",
        "      ## Append the confusion matrix of this fold\t\n",
        "      cm_holder_per_fold.append(cm)\t\n",
        "\n",
        "      ## Store the ground truth and predicted values\t\n",
        "      y_true.append(reshaped_y_test) \n",
        "      y_pred.append(predictions) \t\n",
        "      y_pred_prob.append(predictions_)\t\n",
        "\n",
        "    # Evaluation metrics across all folds\n",
        "    mean_accuracy = np.mean(acc_per_fold)\n",
        "    mean_std = np.std(acc_per_fold)\n",
        "    mean_loss = np.mean(loss_per_fold)\n",
        "    print('Sensor:', sensor_position_number, 'Activity:', activity_number)\n",
        "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "\n",
        "    # Confusion matrix across all folds\n",
        "    class_names = ['0', '1']\t\n",
        "    sum_cm_holder_per_fold = []\t\n",
        "    cm_shape = np.array([len(class_names),len(class_names)])\t\n",
        "    for k in range(len(cm_holder_per_fold)):\t\n",
        "        cm_mask = np.zeros(cm_shape)\t\n",
        "        cm_mask[:cm_holder_per_fold[k].shape[0], :cm_holder_per_fold[k].shape[1]] = cm_holder_per_fold[k]\t\n",
        "        sum_cm_holder_per_fold.append(cm_mask)\t\n",
        "    sum_cm_per_fold = sum(sum_cm_holder_per_fold)\t\n",
        "    figure = plot_confusion_matrix(sum_cm_per_fold, class_names=class_names)\t\n",
        "    #plt.show()  \n",
        "    return mean_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Nx2STpKEiA"
      },
      "source": [
        "## Call the Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mcZ2ccR1OvP"
      },
      "outputs": [],
      "source": [
        "# Call the train function for different sensor/activity combinations and obtain the results.\n",
        "test_scores = []\n",
        "activity_list = [1, 2, 3, 4, 5, 6, 7]\n",
        "sensor_list = [1, 2, 3, 4, 5]\n",
        "for activity in activity_list:\n",
        "  for sensor in sensor_list:\n",
        "    mean_accuracy = get_scores(sensor, activity, full_gd_df)     \n",
        "    test_scores.append((activity, sensor, mean_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "\n",
        "test_scores.insert(0, ('Activity', 'Sensor', 'Mean Accuracy'))\n",
        "print(tabulate(test_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRu7fYWWeDeE",
        "outputId": "42e294a6-4d6a-4254-f997-0a1c8df1cbf6"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "--------  ------  ------------------\n",
            "Activity  Sensor  Mean Accuracy\n",
            "1         1       87.70343555679804\n",
            "1         2       53.752260608009145\n",
            "1         3       67.63110092923611\n",
            "1         4       43.810787453101234\n",
            "1         5       51.1936332934942\n",
            "2         1       87.20614819587031\n",
            "2         2       49.4575042890597\n",
            "2         3       67.45026926451092\n",
            "2         4       43.81078741489313\n",
            "2         5       56.012378976895256\n",
            "3         1       81.22710738426599\n",
            "3         2       52.701464944925064\n",
            "3         3       63.1868125918584\n",
            "3         4       33.3791210101201\n",
            "3         5       57.63546905734322\n",
            "4         1       81.19349087340922\n",
            "4         2       56.96202599549596\n",
            "4         3       48.41772102856938\n",
            "4         4       44.076038476748344\n",
            "4         5       43.58974351332738\n",
            "5         1       89.15008962908878\n",
            "5         2       47.3779381830481\n",
            "5         3       62.61301983760882\n",
            "5         4       75.7736515540343\n",
            "5         5       41.290892851658356\n",
            "6         1       86.98010784161242\n",
            "6         2       60.84990931462638\n",
            "6         3       58.634720497493504\n",
            "6         4       68.21396908698938\n",
            "6         5       41.0256415223464\n",
            "7         1       83.00180789790576\n",
            "7         2       42.63110289090796\n",
            "7         3       60.759492576876774\n",
            "7         4       66.6666662463775\n",
            "7         5       44.69496007913198\n",
            "--------  ------  ------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucrRZKPWfqOM"
      },
      "source": [
        "## Plot the Training and Validation Loss and Accuracy Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isNuPgjNfnwv"
      },
      "outputs": [],
      "source": [
        "# Plot the training and validation loss and accuracy graphs.\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JDgN-d9KUxe"
      },
      "source": [
        "## Plot the ROC-AUC Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx-pGSKIBmdy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr1, tpr1, thresh1 = roc_curve(reshaped_y_test, predictions_, pos_label=1)\n",
        "\n",
        "# roc curve for tpr = fpr \n",
        "random_probs = [0 for i in range(len(reshaped_y_test))]\n",
        "p_fpr, p_tpr, _ = roc_curve(reshaped_y_test, random_probs, pos_label=1)\n",
        "\n",
        "# matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# plot roc curves\n",
        "plt.plot(fpr1, tpr1, linestyle='--', color='orange', label='1D CNN')\n",
        "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
        "# title\n",
        "plt.title('ROC curve')\n",
        "# x label\n",
        "plt.xlabel('False Positive Rate')\n",
        "# y label\n",
        "plt.ylabel('True Positive rate')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('ROC', dpi=300)\n",
        "plt.show();"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}